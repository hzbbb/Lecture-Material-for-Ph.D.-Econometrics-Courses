---------------------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  D:\Dropbox\Dropbox\My documents\Rochester\博五下\TA for ECO 485\Stata Recitation\data\Census_2010 Cleani
> ng.log
  log type:  text
 opened on:  21 Feb 2020, 11:31:43

. 
. 
. /* Census data from China - household level survey - Each observation is a person */
. /* id: personal identifier; hhid: household identifier */
. use "$folder\census2010_1p.dta",clear

. 
. 
. /* Change data format */
. tostring hhid id, format(%100.0g) replace
hhid was double now str18
id was long now str7

. destring id,replace
id: all characters numeric; replaced as long

. 
. /* Labelling */
. label var hhid "The ID of the household"                /* Label for variable */

. 
. label define sex_1 1 "male" 2 "female"                  /* Label for values of a variable */

. tab sex

        sex |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |     24,412       50.88       50.88
          2 |     23,566       49.12      100.00
------------+-----------------------------------
      Total |     47,978      100.00

. label value sex sex_1 

. tab sex

        sex |      Freq.     Percent        Cum.
------------+-----------------------------------
       male |     24,412       50.88       50.88
     female |     23,566       49.12      100.00
------------+-----------------------------------
      Total |     47,978      100.00

. 
. label define sex 1 "male" 

. label define sex 2 "female",add

. label value sex sex 

. 
. /*** Data Management ***/
. describe sex

              storage   display    value
variable name   type    format     label      variable label
---------------------------------------------------------------------------------------------------------------------
sex             byte    %10.0g     sex        

. describe _all

              storage   display    value
variable name   type    format     label      variable label
---------------------------------------------------------------------------------------------------------------------
locationcode    str15   %15s                  
prefect         str4    %9s                   
hhid            str18   %18s                  The ID of the household
hhtype          byte    %10.0g                
relation        byte    %10.0g                
sex             byte    %10.0g     sex        
born_year       int     %8.0g                 
born_month      byte    %8.0g                 
nationality     byte    %10.0g                
living_place    byte    %10.0g                
hukou_place     byte    %10.0g                
hukou_place_c~e long    %10.0g                
migtime         int     %10.0g                
hukoutype       int     %10.0g                
birthplace      byte    %10.0g                
literated       int     %10.0g                
industry        int     %10.0g                
occupation      int     %10.0g                
birth_b         int     %8.0g                 
birth_g         int     %8.0g                 
sur_b           int     %8.0g                 
sur_g           int     %8.0g                 
id              long    %10.0g                
eduy            float   %9.0g                 
income          float   %9.0g                 

. des sex

              storage   display    value
variable name   type    format     label      variable label
---------------------------------------------------------------------------------------------------------------------
sex             byte    %10.0g     sex        

. 
. summarize sex

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
         sex |     47,978    1.491183    .4999275          1          2

. sum sex

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
         sex |     47,978    1.491183    .4999275          1          2

. 
. tabulate sex

        sex |      Freq.     Percent        Cum.
------------+-----------------------------------
       male |     24,412       50.88       50.88
     female |     23,566       49.12      100.00
------------+-----------------------------------
      Total |     47,978      100.00

. tab sex

        sex |      Freq.     Percent        Cum.
------------+-----------------------------------
       male |     24,412       50.88       50.88
     female |     23,566       49.12      100.00
------------+-----------------------------------
      Total |     47,978      100.00

. 
. count if sex==1
  24,412

. 
. kdensity income                                                 /* Kernel-smoothed density function */

. 
. rename eduy education

. 
. gen age=2010-born_year                                  /* Generate new variables */

. 
. gen province=substr(prefect,1,2)                /* String variable functions */

. destring province,replace
province: all characters numeric; replaced as byte

. 
. gen st1="hello"

. 
. gen st2=substr(st1,1,1)                                 /* substr(string, starting point, number of letters) */

. gen st3=substr(st1,1,2)

. gen st4=substr(st1,2,.)

. gen st5=substr(st1,-2,2)

. 
. 
. /* Change sex indicator */
. gen sex1=.
(47,978 missing values generated)

. replace sex1=0 if sex==1
(24,412 real changes made)

. replace sex1=1 if sex==2
(23,566 real changes made)

. 
. order id hhid

. sort id hhid

. 
. drop birthplace                 /* Drop variable */

. drop if literated==2    /* Drop observation */
(2,179 observations deleted)

. 
. 
. /* Simulation - generate an income variable with log-normal distribution */
. gen temp=rnormal()

. gen income1=exp(temp)*10000                     /* Random variable with a log-normal distribution */

. 
. gen rand_num=runiform()                         /* Uniform distribution */

. 
. drop temp

. 
. 
. 
. /** egen function - Generate number of children in the HH **/
. egen avg_income=mean(income)

. egen tot_income=sum(income)

. 
. gen chi=1 if relation==2
(31,631 missing values generated)

. replace chi=0 if relation!=2
(31,631 real changes made)

. egen numchi_hh=sum(chi),by(hhid)                                        /* by: means implement the function in each
>  group of the categorical variable */

. label var numchi_hh "Number of Children in HH"

. 
. 
. /* xfill - Identify first child's information */
. net from https://www.sealedenvelope.com/
---------------------------------------------------------------------------------------------------------------------
https://www.sealedenvelope.com/
Programs from Sealed Envelope Ltd
---------------------------------------------------------------------------------------------------------------------

These programs are provided by Sealed Envelope Ltd.
For more details on their use visit www.sealedenvelope.com

PACKAGES you could -net describe-:
    hl                Hosmer-Lemeshow goodness of fit test
    mlogplot2         Extension to mlogplot to handle two-way interaction terms in mlogit
    reformat          Reformat regression output
    rescale           Rescale categorical variables using numbers found in value labels
    time              Convert strings in HH:MM:SS format to elapsed times and back again
    xcount            Count longitudinal data
    xfill             Fill in static variables in longitudinal data
    xtab              Tabulate longitudinal data
---------------------------------------------------------------------------------------------------------------------

. 
. /* Find who is the first child - the child with oldest birthday */
. tostring born_year born_month, format(%100.0g) replace
born_year was int now str4
born_month was byte now str2

. replace born_month="0"+born_month if length(born_month)==1
(33,591 real changes made)

. gen born_date=born_year+born_month

. destring born_date born_year born_month,replace
born_date: all characters numeric; replaced as long
born_year: all characters numeric; replaced as int
born_month: all characters numeric; replaced as byte

. 
. egen fc_date=min(born_date) if relation==2,by(hhid)
(31631 missing values generated)

. destring hhid,replace
hhid: all characters numeric; replaced as double

. xfill fc_date,i(hhid)

. gen fc=1 if fc_date==born_date & relation==2
(36,913 missing values generated)

. egen temp=sum(fc),by(hhid)

. 
. save "$folder\temp.dta",replace
file D:\Dropbox\Dropbox\My documents\Rochester\博五下\TA for ECO 485\Stata Recitation\data\temp.dta saved

. 
. 
. /*** Regression ***/
. reg education sex

      Source |       SS           df       MS      Number of obs   =    42,662
-------------+----------------------------------   F(1, 42660)     =     73.57
       Model |  652.924556         1  652.924556   Prob > F        =    0.0000
    Residual |  378578.069    42,660  8.87431011   R-squared       =    0.0017
-------------+----------------------------------   Adj R-squared   =    0.0017
       Total |  379230.994    42,661  8.88940704   Root MSE        =     2.979

------------------------------------------------------------------------------
   education |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         sex |  -.2476038   .0288664    -8.58   0.000    -.3041826    -.191025
       _cons |    9.67384   .0451163   214.42   0.000     9.585411    9.762269
------------------------------------------------------------------------------

. reg education sex,r

Linear regression                               Number of obs     =     42,662
                                                F(1, 42660)       =      73.43
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0017
                                                Root MSE          =      2.979

------------------------------------------------------------------------------
             |               Robust
   education |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         sex |  -.2476038   .0288944    -8.57   0.000    -.3042374   -.1909702
       _cons |    9.67384   .0448075   215.90   0.000     9.586016    9.761664
------------------------------------------------------------------------------

. reg education sex,cluster(province)

Linear regression                               Number of obs     =     42,662
                                                F(1, 30)          =      51.71
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0017
                                                Root MSE          =      2.979

                              (Std. Err. adjusted for 31 clusters in province)
------------------------------------------------------------------------------
             |               Robust
   education |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         sex |  -.2476038   .0344337    -7.19   0.000    -.3179269   -.1772808
       _cons |    9.67384   .1085992    89.08   0.000     9.452051    9.895629
------------------------------------------------------------------------------

. reg education sex i.province,r

Linear regression                               Number of obs     =     42,662
                                                F(31, 42630)      =      46.60
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0351
                                                Root MSE          =     2.9298

------------------------------------------------------------------------------
             |               Robust
   education |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         sex |  -.2552653   .0284178    -8.98   0.000    -.3109649   -.1995658
             |
    province |
         12  |   -.872168   .2105039    -4.14   0.000     -1.28476   -.4595763
         13  |  -2.178761   .1442596   -15.10   0.000    -2.461513   -1.896009
         14  |  -1.991238   .1566851   -12.71   0.000    -2.298343   -1.684132
         15  |  -2.123136   .1716351   -12.37   0.000    -2.459544   -1.786727
         21  |  -1.767114   .1574523   -11.22   0.000    -2.075724   -1.458505
         22  |  -1.859742   .1671735   -11.12   0.000    -2.187405   -1.532079
         23  |  -1.842645   .1573283   -11.71   0.000    -2.151011   -1.534278
         31  |   -.755927   .1816526    -4.16   0.000     -1.11197   -.3998843
         32  |   -1.57557   .1490977   -10.57   0.000    -1.867804   -1.283335
         33  |  -2.139932   .1529261   -13.99   0.000     -2.43967   -1.840194
         34  |  -2.451763   .1478477   -16.58   0.000    -2.741548   -2.161979
         35  |  -2.081624   .1639775   -12.69   0.000    -2.403024   -1.760225
         36  |  -2.462105   .1537047   -16.02   0.000     -2.76337   -2.160841
         37  |  -2.215656    .144604   -15.32   0.000    -2.499082   -1.932229
         41  |  -2.182761   .1429756   -15.27   0.000    -2.462996   -1.902526
         42  |  -1.841638   .1525323   -12.07   0.000    -2.140604   -1.542672
         43  |  -2.077867   .1499353   -13.86   0.000    -2.371743   -1.783991
         44  |   -1.83103   .1426534   -12.84   0.000    -2.110633   -1.551426
         45  |  -2.677834   .1529718   -17.51   0.000    -2.977662   -2.378006
         46  |  -2.352686   .1880653   -12.51   0.000    -2.721298   -1.984074
         50  |  -2.465454   .1671091   -14.75   0.000    -2.792991   -2.137917
         51  |  -2.870131   .1435879   -19.99   0.000    -3.151566   -2.588696
         52  |  -3.233467   .1546378   -20.91   0.000    -3.536561   -2.930374
         53  |  -3.245836   .1577383   -20.58   0.000    -3.555006   -2.936666
         54  |  -3.572155    .395229    -9.04   0.000    -4.346811   -2.797498
         61  |  -1.793046   .1598057   -11.22   0.000    -2.106268   -1.479824
         62  |  -2.635732   .1682737   -15.66   0.000    -2.965552   -2.305912
         63  |  -2.704846   .2639141   -10.25   0.000    -3.222122   -2.187569
         64  |  -2.216115   .2388245    -9.28   0.000    -2.684216   -1.748015
         65  |  -2.158217   .1715826   -12.58   0.000    -2.494522   -1.821912
             |
       _cons |   11.82691   .1397904    84.60   0.000     11.55291     12.1009
------------------------------------------------------------------------------

. reg education sex i.province sex#province,r
note: 2.sex#65.province omitted because of collinearity

Linear regression                               Number of obs     =     42,662
                                                F(61, 42600)      =      24.68
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0364
                                                Root MSE          =     2.9289

------------------------------------------------------------------------------
             |               Robust
   education |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         sex |  -.1690262   .2149079    -0.79   0.432    -.5902499    .2521975
             |
    province |
         12  |  -.5610084    .284164    -1.97   0.048    -1.117975   -.0040414
         13  |  -1.814584   .1890234    -9.60   0.000    -2.185074   -1.444094
         14  |  -1.608221   .2087181    -7.71   0.000    -2.017312   -1.199129
         15  |  -1.896115   .2266701    -8.37   0.000    -2.340393   -1.451837
         21  |  -1.298478   .2103304    -6.17   0.000     -1.71073   -.8862266
         22  |  -1.411588    .224815    -6.28   0.000     -1.85223   -.9709462
         23  |  -1.651443   .2094565    -7.88   0.000    -2.061982   -1.240904
         31  |  -.2517776   .2409047    -1.05   0.296    -.7239555    .2204002
         32  |  -1.164755   .1951848    -5.97   0.000    -1.547321   -.7821888
         33  |  -1.736939   .2023897    -8.58   0.000    -2.133627   -1.340251
         34  |  -1.994929   .1960334   -10.18   0.000    -2.379158     -1.6107
         35  |   -1.65047   .2170534    -7.60   0.000    -2.075899   -1.225041
         36  |  -1.874759   .2028497    -9.24   0.000    -2.272348   -1.477169
         37  |  -1.807504    .190474    -9.49   0.000    -2.180837   -1.434171
         41  |  -1.860282   .1882709    -9.88   0.000    -2.229297   -1.491268
         42  |  -1.462389   .1997155    -7.32   0.000    -1.853835   -1.070943
         43  |   -1.67667   .1975317    -8.49   0.000    -2.063836   -1.289504
         44  |  -1.458243   .1877034    -7.77   0.000    -1.826145    -1.09034
         45  |  -2.284788   .2046087   -11.17   0.000    -2.685825   -1.883751
         46  |  -2.052191   .2541462    -8.07   0.000    -2.550323    -1.55406
         50  |  -2.355076    .220436   -10.68   0.000    -2.787135   -1.923017
         51  |  -2.489393    .188337   -13.22   0.000    -2.858537   -2.120249
         52  |  -2.761602   .2039617   -13.54   0.000    -3.161371   -2.361833
         53  |  -2.975694   .2076176   -14.33   0.000    -3.382628   -2.568759
         54  |  -3.604342   .4745022    -7.60   0.000    -4.534375   -2.674308
         61  |  -1.228636   .2111927    -5.82   0.000    -1.642577   -.8146936
         62  |  -2.144465   .2244908    -9.55   0.000    -2.584472   -1.704459
         63  |  -2.178979   .3582309    -6.08   0.000    -2.881119    -1.47684
         64  |  -1.939887   .3235579    -6.00   0.000    -2.574067   -1.305708
         65  |   -1.81618   .2269773    -8.00   0.000     -2.26106     -1.3713
             |
sex#province |
  female#11  |   .7274326   .3435603     2.12   0.034     .0540478    1.400817
  female#12  |   .0668693    .389777     0.17   0.864    -.6971012    .8308398
  female#13  |  -.0458512   .2401571    -0.19   0.849    -.5165638    .4248614
  female#14  |  -.0843049   .2694511    -0.31   0.754    -.6124344    .4438245
  female#15  |   .2460375   .3041062     0.81   0.418    -.3500167    .8420917
  female#21  |  -.2578661   .2711717    -0.95   0.342     -.789368    .2736359
  female#22  |  -.2197368   .2934586    -0.75   0.454    -.7949214    .3554478
  female#23  |    .294744   .2706821     1.09   0.276    -.2357983    .8252862
  female#31  |  -.3455063   .3268688    -1.06   0.291    -.9861756    .2951631
  female#32  |  -.1418141   .2518852    -0.56   0.573    -.6355141     .351886
  female#33  |  -.1246661   .2606823    -0.48   0.632    -.6356086    .3862765
  female#34  |   -.238652   .2485485    -0.96   0.337     -.725812    .2485079
  female#35  |  -.1814876   .2863548    -0.63   0.526    -.7427487    .3797735
  female#36  |  -.5116225   .2624222    -1.95   0.051    -1.025975    .0027301
  female#37  |  -.1346618   .2408843    -0.56   0.576    -.6067998    .3374762
  female#41  |   .0444566   .2369532     0.19   0.851    -.4199763    .5088895
  female#42  |  -.0764393   .2600886    -0.29   0.769    -.5862181    .4333394
  female#43  |  -.1227273   .2537967    -0.48   0.629    -.6201738    .3747193
  female#44  |  -.0634217   .2362048    -0.27   0.788    -.5263877    .3995443
  female#45  |  -.1050094   .2606082    -0.40   0.687    -.6158067    .4057878
  female#46  |   .0923658   .3401458     0.27   0.786    -.5743267    .7590584
  female#50  |    .480295   .2931833     1.64   0.101      -.09435     1.05494
  female#51  |  -.0793338   .2386309    -0.33   0.740    -.5470551    .3883874
  female#52  |  -.2851594   .2648629    -1.08   0.282    -.8042959    .2339771
  female#53  |   .1523308   .2721864     0.56   0.576    -.3811598    .6858214
  female#54  |   .8421031    .788847     1.07   0.286    -.7040525    2.388259
  female#61  |  -.4757744   .2768291    -1.72   0.086    -1.018365    .0668161
  female#62  |  -.3188952   .2960725    -1.08   0.281    -.8992031    .2614126
  female#63  |  -.3963705   .5031318    -0.79   0.431    -1.382519    .5897778
  female#64  |   .1457284   .4503256     0.32   0.746    -.7369186    1.028375
  female#65  |          0  (omitted)
             |
       _cons |    11.3567   .2770473    40.99   0.000     10.81368    11.89972
------------------------------------------------------------------------------

. outreg2 using temp,tex replace keep(sex) ctitle(1)                      /* Latex output of the regression table */
temp.tex
dir : seeout

. 
. reg education sex##province,r

Linear regression                               Number of obs     =     42,662
                                                F(61, 42600)      =      24.68
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0364
                                                Root MSE          =     2.9289

------------------------------------------------------------------------------
             |               Robust
   education |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         sex |
     female  |   .5584064   .2680452     2.08   0.037     .0330325     1.08378
             |
    province |
         12  |  -.5610084    .284164    -1.97   0.048    -1.117975   -.0040414
         13  |  -1.814584   .1890234    -9.60   0.000    -2.185074   -1.444094
         14  |  -1.608221   .2087181    -7.71   0.000    -2.017312   -1.199129
         15  |  -1.896115   .2266701    -8.37   0.000    -2.340393   -1.451837
         21  |  -1.298478   .2103304    -6.17   0.000     -1.71073   -.8862266
         22  |  -1.411588    .224815    -6.28   0.000     -1.85223   -.9709462
         23  |  -1.651443   .2094565    -7.88   0.000    -2.061982   -1.240904
         31  |  -.2517776   .2409047    -1.05   0.296    -.7239555    .2204002
         32  |  -1.164755   .1951848    -5.97   0.000    -1.547321   -.7821888
         33  |  -1.736939   .2023897    -8.58   0.000    -2.133627   -1.340251
         34  |  -1.994929   .1960334   -10.18   0.000    -2.379158     -1.6107
         35  |   -1.65047   .2170534    -7.60   0.000    -2.075899   -1.225041
         36  |  -1.874759   .2028497    -9.24   0.000    -2.272348   -1.477169
         37  |  -1.807504    .190474    -9.49   0.000    -2.180837   -1.434171
         41  |  -1.860282   .1882709    -9.88   0.000    -2.229297   -1.491268
         42  |  -1.462389   .1997155    -7.32   0.000    -1.853835   -1.070943
         43  |   -1.67667   .1975317    -8.49   0.000    -2.063836   -1.289504
         44  |  -1.458243   .1877034    -7.77   0.000    -1.826145    -1.09034
         45  |  -2.284788   .2046087   -11.17   0.000    -2.685825   -1.883751
         46  |  -2.052191   .2541462    -8.07   0.000    -2.550323    -1.55406
         50  |  -2.355076    .220436   -10.68   0.000    -2.787135   -1.923017
         51  |  -2.489393    .188337   -13.22   0.000    -2.858537   -2.120249
         52  |  -2.761602   .2039617   -13.54   0.000    -3.161371   -2.361833
         53  |  -2.975694   .2076176   -14.33   0.000    -3.382628   -2.568759
         54  |  -3.604342   .4745022    -7.60   0.000    -4.534375   -2.674308
         61  |  -1.228636   .2111927    -5.82   0.000    -1.642577   -.8146936
         62  |  -2.144465   .2244908    -9.55   0.000    -2.584472   -1.704459
         63  |  -2.178979   .3582309    -6.08   0.000    -2.881119    -1.47684
         64  |  -1.939887   .3235579    -6.00   0.000    -2.574067   -1.305708
         65  |   -1.81618   .2269773    -8.00   0.000     -2.26106     -1.3713
             |
sex#province |
  female#12  |  -.6605633    .421413    -1.57   0.117    -1.486541    .1654144
  female#13  |  -.7732839   .2886837    -2.68   0.007     -1.33911   -.2074582
  female#14  |  -.8117376   .3134752    -2.59   0.010    -1.426155   -.1973199
  female#15  |  -.4813951     .34372    -1.40   0.161    -1.155093    .1923029
  female#21  |  -.9852987   .3149555    -3.13   0.002    -1.602618   -.3679798
  female#22  |  -.9471694   .3343363    -2.83   0.005    -1.602475   -.2918637
  female#23  |  -.4326886    .314534    -1.38   0.169    -1.049181    .1838042
  female#31  |  -1.072939   .3640138    -2.95   0.003    -1.786413   -.3594646
  female#32  |  -.8692467   .2985113    -2.91   0.004    -1.454335   -.2841587
  female#33  |  -.8520987   .3059708    -2.78   0.005    -1.451807     -.25239
  female#34  |  -.9660847   .2957012    -3.27   0.001    -1.545665   -.3865045
  female#35  |  -.9089202   .3281188    -2.77   0.006    -1.552039    -.265801
  female#36  |  -1.239055   .3074544    -4.03   0.000    -1.841672   -.6364384
  female#37  |  -.8620944   .2892889    -2.98   0.003    -1.429106   -.2950824
  female#41  |   -.682976   .2860238    -2.39   0.017    -1.243588   -.1223636
  female#42  |   -.803872   .3054651    -2.63   0.009    -1.402589   -.2051544
  female#43  |  -.8501599    .300126    -2.83   0.005    -1.438413   -.2619071
  female#44  |  -.7908543   .2854042    -2.77   0.006    -1.350252   -.2314566
  female#45  |   -.832442   .3059076    -2.72   0.007    -1.432027   -.2328571
  female#46  |  -.6350668   .3759814    -1.69   0.091    -1.371998    .1018642
  female#50  |  -.2471376   .3340947    -0.74   0.459    -.9019698    .4076945
  female#51  |  -.8067665   .2874153    -2.81   0.005    -1.370106   -.2434269
  female#52  |  -1.012592   .3095403    -3.27   0.001    -1.619297    -.405887
  female#53  |  -.5751018   .3158295    -1.82   0.069    -1.194134    .0439301
  female#54  |   .1146705   .8049487     0.14   0.887    -1.463045    1.692386
  female#61  |  -1.203207   .3198393    -3.76   0.000    -1.830098   -.5763157
  female#62  |  -1.046328   .3366329    -3.11   0.002    -1.706135   -.3865207
  female#63  |  -1.123803   .5280194    -2.13   0.033    -2.158731   -.0888748
  female#64  |  -.5817042   .4779706    -1.22   0.224    -1.518536    .3551276
  female#65  |  -.7274326   .3435603    -2.12   0.034    -1.400817   -.0540478
             |
       _cons |   11.18768   .1748422    63.99   0.000     10.84498    11.53037
------------------------------------------------------------------------------

. 
. /* Regression with high-dimensional FE */
. ssc install ftools
checking ftools consistency and verifying not already installed...
all files already exist and are up to date.

. ssc install reghdfe
checking reghdfe consistency and verifying not already installed...
all files already exist and are up to date.

. 
. gen prefect_age=prefect+age
type mismatch
r(109);

end of do-file

r(109);

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. destring age,replace
age already numeric; no replace

. gen prefect_age=prefect+age
type mismatch
r(109);

end of do-file

r(109);

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. tostring age,replace
age was float now str3

. 
end of do-file

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. gen prefect_age=prefect+age

. 
end of do-file

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. destring prefect_age,replace
prefect_age: all characters numeric; replaced as long

. 
end of do-file

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. reg education sex i.prefect_age,r
maxvar too small
    You have attempted to use an interaction with too many levels or attempted to fit a model with too many
    variables.  You need to increase maxvar; it is currently 5000.  Use set maxvar; see help maxvar.

    If you are using factor variables and included an interaction that has lots of missing cells, either increase
    maxvar or set emptycells drop to reduce the required matrix size; see help set emptycells.

    If you are using factor variables, you might have accidentally treated a continuous variable as a categorical,
    resulting in lots of categories.  Use the c. operator on such variables.
r(907);

end of do-file

r(907);

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. reghdfe education sex,absorb(prefect_age) r
(dropped 6289 singleton observations)
invalid options: r
r(9);

end of do-file

r(9);

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. reghdfe education sex,absorb(prefect_age) vce(r)
(dropped 6289 singleton observations)
(MWFE estimator converged in 1 iterations)

HDFE Linear regression                            Number of obs   =     36,373
Absorbing 1 HDFE group                            F(   1,  26792) =     137.76
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.5120
                                                  Adj R-squared   =     0.3374
                                                  Within R-sq.    =     0.0054
                                                  Root MSE        =     2.4183

------------------------------------------------------------------------------
             |               Robust
   education |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         sex |   -.355277    .030269   -11.74   0.000    -.4146059   -.2959481
       _cons |   9.979793   .0468649   212.95   0.000     9.887935    10.07165
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
 prefect_age |      9580           0        9580     |
-----------------------------------------------------+

. 
end of do-file

. tab sex

        sex |      Freq.     Percent        Cum.
------------+-----------------------------------
       male |     23,817       52.00       52.00
     female |     21,982       48.00      100.00
------------+-----------------------------------
      Total |     45,799      100.00

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. /* Linear GMM */
. ivregress 2sls numchi_hh nationality (education=born_year born_month),r

Instrumental variables (2SLS) regression          Number of obs   =     42,662
                                                  Wald chi2(2)    =     609.20
                                                  Prob > chi2     =     0.0000
                                                  R-squared       =          .
                                                  Root MSE        =     1.8494

------------------------------------------------------------------------------
             |               Robust
   numchi_hh |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   education |   .4230078   .0179975    23.50   0.000     .3877334    .4582823
 nationality |   .0449905   .0033447    13.45   0.000     .0384351    .0515459
       _cons |  -2.556695   .1677228   -15.24   0.000    -2.885425   -2.227964
------------------------------------------------------------------------------
Instrumented:  education
Instruments:   nationality born_year born_month

. ivregress gmm numchi_hh nationality (education=born_year born_month),r

Instrumental variables (GMM) regression           Number of obs   =     42,662
                                                  Wald chi2(2)    =     608.40
                                                  Prob > chi2     =     0.0000
                                                  R-squared       =          .
GMM weight matrix: Robust                         Root MSE        =     1.8482

------------------------------------------------------------------------------
             |               Robust
   numchi_hh |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   education |   .4225166   .0179868    23.49   0.000     .3872631    .4577701
 nationality |   .0448907   .0033391    13.44   0.000     .0383462    .0514352
       _cons |  -2.552566   .1676236   -15.23   0.000    -2.881102   -2.224029
------------------------------------------------------------------------------
Instrumented:  education
Instruments:   nationality born_year born_month

. ivregress gmm numchi_hh nationality (education sex=born_year born_month),r

Instrumental variables (GMM) regression           Number of obs   =     42,662
                                                  Wald chi2(3)    =      16.53
                                                  Prob > chi2     =     0.0009
                                                  R-squared       =          .
GMM weight matrix: Robust                         Root MSE        =      11.41

------------------------------------------------------------------------------
             |               Robust
   numchi_hh |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   education |   -.100705   .8085039    -0.12   0.901    -1.685344    1.483934
         sex |   22.76503   34.80703     0.65   0.513    -45.45549    90.98556
 nationality |   .0165991   .0469912     0.35   0.724     -.075502    .1087003
       _cons |  -31.34796   44.03401    -0.71   0.477     -117.653    54.95712
------------------------------------------------------------------------------
Instrumented:  education sex
Instruments:   nationality born_year born_month

. 
. 
. /*Postregression estimation */
. reg education sex nationality

      Source |       SS           df       MS      Number of obs   =    42,662
-------------+----------------------------------   F(2, 42659)     =    104.57
       Model |  1850.16826         2   925.08413   Prob > F        =    0.0000
    Residual |  377380.826    42,659  8.84645269   R-squared       =    0.0049
-------------+----------------------------------   Adj R-squared   =    0.0048
       Total |  379230.994    42,661  8.88940704   Root MSE        =    2.9743

------------------------------------------------------------------------------
   education |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         sex |  -.2474562   .0288211    -8.59   0.000    -.3039461   -.1909663
 nationality |  -.0512688    .004407   -11.63   0.000    -.0599067    -.042631
       _cons |   9.759668   .0456456   213.81   0.000     9.670201    9.849134
------------------------------------------------------------------------------

. predict pre,xb

. test sex=1

 ( 1)  sex = 1

       F(  1, 42659) = 1873.40
            Prob > F =    0.0000

. test (sex=1) (nationality=0)

 ( 1)  sex = 1
 ( 2)  nationality = 0

       F(  2, 42659) = 1004.59
            Prob > F =    0.0000

. 
end of do-file

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. /* Local */
. forvalues i=1(1)10{
  2.         a=i+1
  3.         display a
  4.         }
command a is unrecognized
r(199);

end of do-file

r(199);

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. local t=10

. forvalues i=1(1)`t'{
  2.         local a=`i'+1
  3.         display `a'
  4.         }
2
3
4
5
6
7
8
9
10
11

. 
end of do-file

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. ***** Estimating Gravity Equation *********
. ***** Data: China Census 2010     *********
. ***** Zibin Huang 2019.9.9        *********
. 
. 
. ***********************************************************************
. * Load Cleaned Migration Flow Data from Census 2010
. ***********************************************************************
. 
. clear

. set more off

. clear matrix

. clear mata

. 
. /*
> cap ado uninstall ftools     /* Install package for high dimensional fixed effect regression */
> cap ado uninstall reghdfe
> cap ado uninstall ppmlhdfe
> 
> ssc install ftools
> ssc install reghdfe
> ssc install ppmlhdfe
> 
> clear all
> ftools, compile
> reghdfe, compile
> */
. 
. 
. global folder "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model"

. cd "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity E
> quation"
D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity Equatio
> n

. 
. import delimited "$folder\Cleaned Data\gravity.csv",clear
(185 vars, 161,312 obs)

. 
. tostring living_city hukou_city,replace
living_city was int now str4
hukou_city was int now str4

. 
. merge m:1 living_city college using "$folder\Cleaned Data\city_skill_wage_2010_2005imputed.dta"
(note: variable college was byte, now float to accommodate using data's values)

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                           161,312  (_merge==3)
    -----------------------------------------

. *merge m:1 living_city college using "$folder\Cleaned Data\2010_wage_city_skill.dta"
. drop _merge

. 
. *keep hukou_city hukou_city_num living_city living_city_num city_pair college mig city_skill_wage expected_outmig_u
>  expected_stay_u
. 
. /*
> /* Calculate Overall Migration Rate */
> egen total_people=sum(mig)
> egen total_stayer=sum(mig) if living_city==hukou_city                   /* Number of stayers */
> gen x=1
> xfill total_stayer,i(x)
> drop x
> */
. 
. replace city_skill_wage=imputed_city_skill_wage_2010
(161,312 real changes made)

. 
. save "$folder\Cleaned Data\data_for_gravity.dta",replace
file D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\data_for_gravity.d
> ta saved

. 
end of do-file

. do "C:\Users\huang\AppData\Local\Temp\STDb28_000000.tmp"

. ***********************************************************************
. * Generate Variables in Regression
. ***********************************************************************
. 
. *-- Wage
. gen l_city_skill_wage=log(city_skill_wage)

. 
. *-- Migration flows
. gen mig_perturb=mig

. replace mig_perturb=0 if mig==0                         /* If migration flow is zero, assign a very small number be
> fore taking log */
(0 real changes made)

. gen l_mig_perturb=log(mig_perturb)
(147,165 missing values generated)

. 
. egen hukou_skill=group(hukou_city college)

. bysort hukou_skill: egen mig_hukou=sum(mig_perturb)

. sort hukou_city living_city college

. gen pi_ijs = mig_perturb/mig_hukou

. gen l_pi_ijs=log(pi_ijs)
(147,165 missing values generated)

. 
. *-- Human capital
. *gen kijs_star=expected_outmig_u if living_city!=hukou_city
. *replace kijs_star=expected_stay_u if living_city==hukou_city
. *sum kijs
. *replace kijs=kijs+1.4                                  /* Normalizing kijs to be positive */
. *gen kijs=exp(kijs_star)
. *gen l_kijs=log(kijs)
. 
. *-- Fixed effects
. egen feij=group(city_pair)

. egen feis=group(hukou_city college)

. egen fejs=group(living_city college)

. 
. gen weight=mig+1

. 
. save "$folder\Cleaned Data\data_for_gravity.dta",replace
file D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\data_for_gravity.d
> ta saved

. 
. 
. ***********************************************************************
. * Gravity Equation Estimation
. ***********************************************************************
. *mat coef_gravity
. forvalues i=1(1)50{
  2.         ppmlhdfe pi_ijs l_city_skill_wage l_kijs`i',absorb(feij feis) vce(r)                                    
>                 /* A gravity equation with fixed effects on original city-destination city level and original city-
> skill level */
  3.         *outreg2 using Gravity,tex replace keep(l_city_skill_wage l_kijs) ctitle(1) addtext(Original-Destination
>  City Fixed Effects, YES, Original City-Skill Fixed Effects, YES)
.         if `i'==1{
  4.         mat coef_gravity=e(b)
  5.         }
  6.         else{
  7.         mat a=e(b)
  8.         mat coef_gravity=[coef_gravity \ a]
  9.         }
 10.         *testnl _b[l_kijs]/_b[l_city_skill_wage]=0
. }
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0016e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.8035e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7624e+01  eps = 3.54e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.53      
Iteration 4:   deviance = 5.4291e+01  eps = 6.14e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.71      
Iteration 5:   deviance = 5.3993e+01  eps = 5.51e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.51      
Iteration 6:   deviance = 5.3982e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.99      
Iteration 7:   deviance = 5.3982e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.14      
Iteration 8:   deviance = 5.3982e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.16   S  
Iteration 9:   deviance = 5.3982e+01  eps = 2.27e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.16   S  
Iteration 10:  deviance = 5.3982e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.16   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     766.07
Deviance             =  53.98159003               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0697691               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.442192    .081193    17.76   0.000     1.283056    1.601327
          l_kijs1 |   2.379371   .0979719    24.29   0.000      2.18735    2.571392
            _cons |  -14.63583   .8005944   -18.28   0.000    -16.20497    -13.0667
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0008e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.7951e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7516e+01  eps = 3.55e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.52      
Iteration 4:   deviance = 5.4177e+01  eps = 6.16e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.70      
Iteration 5:   deviance = 5.3879e+01  eps = 5.53e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.50      
Iteration 6:   deviance = 5.3868e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.98      
Iteration 7:   deviance = 5.3868e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.13      
Iteration 8:   deviance = 5.3868e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.14   S  
Iteration 9:   deviance = 5.3868e+01  eps = 2.27e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.14   S  
Iteration 10:  deviance = 5.3868e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.14   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     786.93
Deviance             =  53.86770622               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0128272               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |     1.4374   .0810496    17.73   0.000     1.278546    1.596254
          l_kijs2 |   2.369452   .0958553    24.72   0.000     2.181579    2.557325
            _cons |  -15.34249   .8050037   -19.06   0.000    -16.92027   -13.76471
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9982e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7572e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.7012e+01  eps = 3.61e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.59      
Iteration 4:   deviance = 5.3644e+01  eps = 6.28e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.79      
Iteration 5:   deviance = 5.3344e+01  eps = 5.62e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.60      
Iteration 6:   deviance = 5.3333e+01  eps = 2.19e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 7:   deviance = 5.3333e+01  eps = 3.58e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.23      
Iteration 8:   deviance = 5.3333e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.25   S  
Iteration 9:   deviance = 5.3333e+01  eps = 2.39e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.25   S  
Iteration 10:  deviance = 5.3333e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.25   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     827.10
Deviance             =  53.33260492               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7452765               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.411942   .0811432    17.40   0.000     1.252904     1.57098
          l_kijs3 |   2.644313   .1031874    25.63   0.000      2.44207    2.846557
            _cons |  -15.35765    .807763   -19.01   0.000    -16.94083   -13.77446
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0016e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8036e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7625e+01  eps = 3.54e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.52      
Iteration 4:   deviance = 5.4292e+01  eps = 6.14e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.71      
Iteration 5:   deviance = 5.3995e+01  eps = 5.51e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.51      
Iteration 6:   deviance = 5.3983e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.98      
Iteration 7:   deviance = 5.3983e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.14      
Iteration 8:   deviance = 5.3983e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.15   S  
Iteration 9:   deviance = 5.3983e+01  eps = 2.26e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.15   S  
Iteration 10:  deviance = 5.3983e+01  eps = 1.36e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.15   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     767.46
Deviance             =  53.98292831               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0704382               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.442342   .0811734    17.77   0.000     1.283245    1.601439
          l_kijs4 |   2.369644   .0974644    24.31   0.000     2.178617    2.560671
            _cons |  -14.72779    .801055   -18.39   0.000    -16.29783   -13.15775
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9975e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.7455e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.09      
Iteration 3:   deviance = 5.6854e+01  eps = 3.62e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.61      
Iteration 4:   deviance = 5.3477e+01  eps = 6.31e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.83      
Iteration 5:   deviance = 5.3176e+01  eps = 5.65e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.63      
Iteration 6:   deviance = 5.3165e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.11      
Iteration 7:   deviance = 5.3165e+01  eps = 3.61e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.27      
Iteration 8:   deviance = 5.3165e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.29   S  
Iteration 9:   deviance = 5.3165e+01  eps = 2.44e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.29   S  
Iteration 10:  deviance = 5.3165e+01  eps = 1.38e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.29   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     834.41
Deviance             =  53.16457032               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6612592               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.402435   .0812133    17.27   0.000      1.24326     1.56161
          l_kijs5 |   2.746473   .1063877    25.82   0.000     2.537957    2.954989
            _cons |   -15.1313   .8073468   -18.74   0.000    -16.71367   -13.54893
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0001e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7825e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.06      
Iteration 3:   deviance = 5.7345e+01  eps = 3.57e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.56      
Iteration 4:   deviance = 5.3995e+01  eps = 6.20e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.76      
Iteration 5:   deviance = 5.3697e+01  eps = 5.56e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.56      
Iteration 6:   deviance = 5.3685e+01  eps = 2.17e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.04      
Iteration 7:   deviance = 5.3685e+01  eps = 3.54e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.19      
Iteration 8:   deviance = 5.3685e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.21   S  
Iteration 9:   deviance = 5.3685e+01  eps = 2.33e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.21   S  
Iteration 10:  deviance = 5.3685e+01  eps = 1.37e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.21   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     790.56
Deviance             =  53.68484901               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.9213986               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.428851   .0812222    17.59   0.000     1.269658    1.588043
          l_kijs6 |   2.519677   .1014069    24.85   0.000     2.320923    2.718431
            _cons |  -14.76724   .8029192   -18.39   0.000    -16.34093   -13.19355
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9980e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7543e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.6973e+01  eps = 3.61e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.59      
Iteration 4:   deviance = 5.3603e+01  eps = 6.29e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.80      
Iteration 5:   deviance = 5.3303e+01  eps = 5.63e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.60      
Iteration 6:   deviance = 5.3292e+01  eps = 2.20e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.08      
Iteration 7:   deviance = 5.3291e+01  eps = 3.59e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.24      
Iteration 8:   deviance = 5.3291e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.26   S  
Iteration 9:   deviance = 5.3291e+01  eps = 2.40e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.26   S  
Iteration 10:  deviance = 5.3291e+01  eps = 1.38e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.26   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     829.33
Deviance             =  53.29143354               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7246908               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.409735   .0811572    17.37   0.000      1.25067      1.5688
          l_kijs7 |   2.667993   .1038933    25.68   0.000     2.464366     2.87162
            _cons |  -15.32238   .8077682   -18.97   0.000    -16.90558   -13.73919
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0042e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8403e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.02      
Iteration 3:   deviance = 5.8110e+01  eps = 3.49e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.47      
Iteration 4:   deviance = 5.4804e+01  eps = 6.03e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.64      
Iteration 5:   deviance = 5.4508e+01  eps = 5.42e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.43      
Iteration 6:   deviance = 5.4497e+01  eps = 2.11e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.90      
Iteration 7:   deviance = 5.4497e+01  eps = 3.45e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 8:   deviance = 5.4497e+01  eps = 1.04e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.07   S  
Iteration 9:   deviance = 5.4497e+01  eps = 2.18e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.07   S  
Iteration 10:  deviance = 5.4497e+01  eps = 1.35e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.07   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     721.08
Deviance             =  54.49674878               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.3273484               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.46243   .0811134    18.03   0.000      1.30345    1.621409
          l_kijs8 |   2.136026    .092044    23.21   0.000     1.955623    2.316429
            _cons |  -14.36783   .7959561   -18.05   0.000    -15.92788   -12.80779
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9967e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.7338e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.10      
Iteration 3:   deviance = 5.6701e+01  eps = 3.64e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.62      
Iteration 4:   deviance = 5.3316e+01  eps = 6.35e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.84      
Iteration 5:   deviance = 5.3015e+01  eps = 5.68e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.65      
Iteration 6:   deviance = 5.3003e+01  eps = 2.22e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.13      
Iteration 7:   deviance = 5.3003e+01  eps = 3.63e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.29      
Iteration 8:   deviance = 5.3003e+01  eps = 1.11e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.31   S  
Iteration 9:   deviance = 5.3003e+01  eps = 2.47e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.31   S  
Iteration 10:  deviance = 5.3003e+01  eps = 1.38e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.31   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     850.66
Deviance             =    53.002958               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.5804531               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.39366   .0811711    17.17   0.000     1.234567    1.552752
          l_kijs9 |   2.802573   .1071482    26.16   0.000     2.592567     3.01258
            _cons |  -15.39295   .8094529   -19.02   0.000    -16.97945   -13.80645
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9999e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7782e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.7286e+01  eps = 3.58e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.57      
Iteration 4:   deviance = 5.3933e+01  eps = 6.22e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3634e+01  eps = 5.57e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.58      
Iteration 6:   deviance = 5.3622e+01  eps = 2.18e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 7:   deviance = 5.3622e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.21      
Iteration 8:   deviance = 5.3622e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.23   S  
Iteration 9:   deviance = 5.3622e+01  eps = 2.35e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.23   S  
Iteration 10:  deviance = 5.3622e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.23   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     791.95
Deviance             =  53.62208233               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8900152               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.425415   .0812675    17.54   0.000     1.266134    1.584697
         l_kijs10 |   2.568469   .1031811    24.89   0.000     2.366238    2.770701
            _cons |  -14.58125   .8023243   -18.17   0.000    -16.15378   -13.00872
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9992e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7728e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.7223e+01  eps = 3.58e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.54      
Iteration 4:   deviance = 5.3868e+01  eps = 6.23e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.73      
Iteration 5:   deviance = 5.3569e+01  eps = 5.58e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.53      
Iteration 6:   deviance = 5.3558e+01  eps = 2.17e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.01      
Iteration 7:   deviance = 5.3558e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.17      
Iteration 8:   deviance = 5.3558e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.18   S  
Iteration 9:   deviance = 5.3558e+01  eps = 2.32e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.18   S  
Iteration 10:  deviance = 5.3558e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.18   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     820.61
Deviance             =  53.55756338               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8577557               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.422886   .0809678    17.57   0.000     1.264192     1.58158
         l_kijs11 |   2.482619   .0976221    25.43   0.000     2.291284    2.673955
            _cons |  -15.85852   .8094711   -19.59   0.000    -17.44506   -14.27199
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0028e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8222e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.02      
Iteration 3:   deviance = 5.7875e+01  eps = 3.52e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.47      
Iteration 4:   deviance = 5.4556e+01  eps = 6.08e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.64      
Iteration 5:   deviance = 5.4260e+01  eps = 5.46e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.44      
Iteration 6:   deviance = 5.4249e+01  eps = 2.13e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.91      
Iteration 7:   deviance = 5.4248e+01  eps = 3.47e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 8:   deviance = 5.4248e+01  eps = 1.05e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.08   S  
Iteration 9:   deviance = 5.4248e+01  eps = 2.20e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.08   S  
Iteration 10:  deviance = 5.4248e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.08   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     753.45
Deviance             =  54.24847516               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.2032116               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.453055   .0810008    17.94   0.000     1.294296    1.611814
         l_kijs12 |   2.184334   .0912077    23.95   0.000      2.00557    2.363098
            _cons |  -15.16958   .8018831   -18.92   0.000    -16.74124   -13.59792
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9979e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7534e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.6966e+01  eps = 3.61e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.58      
Iteration 4:   deviance = 5.3596e+01  eps = 6.29e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3296e+01  eps = 5.63e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.59      
Iteration 6:   deviance = 5.3284e+01  eps = 2.19e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 7:   deviance = 5.3284e+01  eps = 3.58e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.3284e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.24   S  
Iteration 9:   deviance = 5.3284e+01  eps = 2.39e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.24   S  
Iteration 10:  deviance = 5.3284e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.24   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     838.33
Deviance             =  53.28384116               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7208946               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.409527   .0810522    17.39   0.000     1.250668    1.568387
         l_kijs13 |   2.635108   .1019898    25.84   0.000     2.435211    2.835004
            _cons |  -15.73726   .8100522   -19.43   0.000    -17.32493   -14.14959
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0029e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8204e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7845e+01  eps = 3.52e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.51      
Iteration 4:   deviance = 5.4524e+01  eps = 6.09e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.69      
Iteration 5:   deviance = 5.4228e+01  eps = 5.47e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.49      
Iteration 6:   deviance = 5.4216e+01  eps = 2.13e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.96      
Iteration 7:   deviance = 5.4216e+01  eps = 3.48e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.12      
Iteration 8:   deviance = 5.4216e+01  eps = 1.05e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.13   S  
Iteration 9:   deviance = 5.4216e+01  eps = 2.24e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.13   S  
Iteration 10:  deviance = 5.4216e+01  eps = 1.35e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.13   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     741.28
Deviance             =  54.21602255               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.1869853               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.45137   .0812213    17.87   0.000     1.292179    1.610561
         l_kijs14 |   2.301034   .0970212    23.72   0.000     2.110876    2.491192
            _cons |  -14.19537   .7970057   -17.81   0.000    -15.75748   -12.63327
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0028e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8202e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.7844e+01  eps = 3.52e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.51      
Iteration 4:   deviance = 5.4523e+01  eps = 6.09e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.69      
Iteration 5:   deviance = 5.4226e+01  eps = 5.47e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.48      
Iteration 6:   deviance = 5.4215e+01  eps = 2.13e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.96      
Iteration 7:   deviance = 5.4215e+01  eps = 3.48e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.11      
Iteration 8:   deviance = 5.4215e+01  eps = 1.05e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.13   S  
Iteration 9:   deviance = 5.4215e+01  eps = 2.23e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.13   S  
Iteration 10:  deviance = 5.4215e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.13   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     743.61
Deviance             =  54.21455972               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.1862539               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.451577   .0811949    17.88   0.000     1.292438    1.610716
         l_kijs15 |   2.286353   .0962046    23.77   0.000     2.097795     2.47491
            _cons |  -14.34947   .7977476   -17.99   0.000    -15.91302   -12.78591
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9966e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7367e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.6747e+01  eps = 3.63e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.59      
Iteration 4:   deviance = 5.3365e+01  eps = 6.34e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.81      
Iteration 5:   deviance = 5.3064e+01  eps = 5.67e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.61      
Iteration 6:   deviance = 5.3053e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.09      
Iteration 7:   deviance = 5.3052e+01  eps = 3.61e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.25      
Iteration 8:   deviance = 5.3052e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.26   S  
Iteration 9:   deviance = 5.3052e+01  eps = 2.43e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.26   S  
Iteration 10:  deviance = 5.3052e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.26   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     863.51
Deviance             =  53.05244516               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6051966               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.397022   .0809729    17.25   0.000     1.238318    1.555726
         l_kijs16 |   2.716076   .1030911    26.35   0.000     2.514021    2.918131
            _cons |  -16.14111   .8133223   -19.85   0.000    -17.73519   -14.54702
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9980e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7541e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.6970e+01  eps = 3.61e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.59      
Iteration 4:   deviance = 5.3600e+01  eps = 6.29e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.80      
Iteration 5:   deviance = 5.3300e+01  eps = 5.63e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.60      
Iteration 6:   deviance = 5.3288e+01  eps = 2.20e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.08      
Iteration 7:   deviance = 5.3288e+01  eps = 3.59e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.24      
Iteration 8:   deviance = 5.3288e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.26   S  
Iteration 9:   deviance = 5.3288e+01  eps = 2.40e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.26   S  
Iteration 10:  deviance = 5.3288e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.26   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     829.51
Deviance             =   53.2881008               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7230245               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.409554   .0811584    17.37   0.000     1.250486    1.568621
         l_kijs17 |   2.669934   .1039518    25.68   0.000     2.466192    2.873675
            _cons |  -15.31916   .8077667   -18.96   0.000    -16.90235   -13.73597
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0014e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8043e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.02      
Iteration 3:   deviance = 5.7640e+01  eps = 3.54e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.49      
Iteration 4:   deviance = 5.4308e+01  eps = 6.13e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.66      
Iteration 5:   deviance = 5.4011e+01  eps = 5.50e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.46      
Iteration 6:   deviance = 5.4000e+01  eps = 2.14e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.93      
Iteration 7:   deviance = 5.4000e+01  eps = 3.49e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.08      
Iteration 8:   deviance = 5.4000e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.10   S  
Iteration 9:   deviance = 5.4000e+01  eps = 2.23e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.10   S  
Iteration 10:  deviance = 5.4000e+01  eps = 1.36e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.10   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     784.24
Deviance             =  53.99951893               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0787335               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.442244   .0808925    17.83   0.000     1.283698     1.60079
         l_kijs18 |   2.255924   .0916322    24.62   0.000     2.076328     2.43552
            _cons |  -15.77253   .8068167   -19.55   0.000    -17.35386   -14.19119
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0009e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7946e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.7507e+01  eps = 3.55e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.54      
Iteration 4:   deviance = 5.4167e+01  eps = 6.17e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.73      
Iteration 5:   deviance = 5.3869e+01  eps = 5.53e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.53      
Iteration 6:   deviance = 5.3857e+01  eps = 2.16e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.00      
Iteration 7:   deviance = 5.3857e+01  eps = 3.52e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.16      
Iteration 8:   deviance = 5.3857e+01  eps = 1.07e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.17   S  
Iteration 9:   deviance = 5.3857e+01  eps = 2.29e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.17   S  
Iteration 10:  deviance = 5.3857e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.17   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     777.66
Deviance             =   53.8569105               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0074293               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.43683   .0811919    17.70   0.000     1.277697    1.595963
         l_kijs19 |   2.431637   .0990521    24.55   0.000     2.237499    2.625776
            _cons |  -14.76361   .8019594   -18.41   0.000    -16.33542   -13.19179
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0007e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.7938e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.7501e+01  eps = 3.55e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.51      
Iteration 4:   deviance = 5.4161e+01  eps = 6.17e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.69      
Iteration 5:   deviance = 5.3863e+01  eps = 5.53e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.49      
Iteration 6:   deviance = 5.3852e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.96      
Iteration 7:   deviance = 5.3852e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.12      
Iteration 8:   deviance = 5.3852e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.13   S  
Iteration 9:   deviance = 5.3852e+01  eps = 2.26e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.13   S  
Iteration 10:  deviance = 5.3852e+01  eps = 1.36e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.13   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     793.78
Deviance             =   53.8515917               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0047699               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.436349    .080967    17.74   0.000     1.277656    1.595041
         l_kijs20 |   2.347796   .0944829    24.85   0.000     2.162613    2.532979
            _cons |  -15.64693   .8068245   -19.39   0.000    -17.22828   -14.06559
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9991e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7721e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.7214e+01  eps = 3.58e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.54      
Iteration 4:   deviance = 5.3859e+01  eps = 6.23e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.74      
Iteration 5:   deviance = 5.3560e+01  eps = 5.58e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.54      
Iteration 6:   deviance = 5.3548e+01  eps = 2.17e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.01      
Iteration 7:   deviance = 5.3548e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.17      
Iteration 8:   deviance = 5.3548e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.18   S  
Iteration 9:   deviance = 5.3548e+01  eps = 2.32e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.18   S  
Iteration 10:  deviance = 5.3548e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.18   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     820.30
Deviance             =  53.54795981               Prob > chi2     =     0.0000
Log pseudolikelihood =  -958.852954               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.422506   .0809851    17.57   0.000     1.263778    1.581234
         l_kijs21 |    2.49253   .0980184    25.43   0.000     2.300418    2.684643
            _cons |  -15.80717   .8092229   -19.53   0.000    -17.39322   -14.22112
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0034e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8299e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.02      
Iteration 3:   deviance = 5.7975e+01  eps = 3.51e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.48      
Iteration 4:   deviance = 5.4661e+01  eps = 6.06e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.64      
Iteration 5:   deviance = 5.4365e+01  eps = 5.44e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.44      
Iteration 6:   deviance = 5.4354e+01  eps = 2.12e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.91      
Iteration 7:   deviance = 5.4354e+01  eps = 3.46e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 8:   deviance = 5.4354e+01  eps = 1.04e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.08   S  
Iteration 9:   deviance = 5.4354e+01  eps = 2.19e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.08   S  
Iteration 10:  deviance = 5.4354e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.08   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     738.14
Deviance             =  54.35364965               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.2557989               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.457284   .0810778    17.97   0.000     1.298375    1.616194
         l_kijs22 |   2.173093   .0920472    23.61   0.000     1.992684    2.353502
            _cons |  -14.73887   .7988371   -18.45   0.000    -16.30456   -13.17317
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9998e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7790e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.06      
Iteration 3:   deviance = 5.7301e+01  eps = 3.58e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.56      
Iteration 4:   deviance = 5.3950e+01  eps = 6.21e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.75      
Iteration 5:   deviance = 5.3651e+01  eps = 5.57e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.55      
Iteration 6:   deviance = 5.3639e+01  eps = 2.17e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.03      
Iteration 7:   deviance = 5.3639e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.19      
Iteration 8:   deviance = 5.3639e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.20   S  
Iteration 9:   deviance = 5.3639e+01  eps = 2.33e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.20   S  
Iteration 10:  deviance = 5.3639e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.20   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     799.69
Deviance             =  53.63923549               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8985918               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.427042    .081159    17.58   0.000     1.267973     1.58611
         l_kijs23 |   2.512858   .1003898    25.03   0.000     2.316098    2.709618
            _cons |  -15.09043   .8048319   -18.75   0.000    -16.66788   -13.51299
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0020e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8086e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7691e+01  eps = 3.54e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.52      
Iteration 4:   deviance = 5.4361e+01  eps = 6.12e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.71      
Iteration 5:   deviance = 5.4064e+01  eps = 5.50e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.50      
Iteration 6:   deviance = 5.4053e+01  eps = 2.14e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.98      
Iteration 7:   deviance = 5.4052e+01  eps = 3.50e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.14      
Iteration 8:   deviance = 5.4052e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.15   S  
Iteration 9:   deviance = 5.4052e+01  eps = 2.26e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.15   S  
Iteration 10:  deviance = 5.4052e+01  eps = 1.36e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.15   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     758.73
Deviance             =   54.0523474               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.1051478               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.445079   .0812017    17.80   0.000     1.285926    1.604231
         l_kijs24 |   2.354425   .0976139    24.12   0.000     2.163105    2.545745
            _cons |  -14.51521   .7995693   -18.15   0.000    -16.08234   -12.94809
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0012e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8026e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.02      
Iteration 3:   deviance = 5.7619e+01  eps = 3.54e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.48      
Iteration 4:   deviance = 5.4287e+01  eps = 6.14e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.65      
Iteration 5:   deviance = 5.3990e+01  eps = 5.50e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.45      
Iteration 6:   deviance = 5.3978e+01  eps = 2.14e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.92      
Iteration 7:   deviance = 5.3978e+01  eps = 3.49e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 8:   deviance = 5.3978e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.09   S  
Iteration 9:   deviance = 5.3978e+01  eps = 2.23e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.09   S  
Iteration 10:  deviance = 5.3978e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.09   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     791.90
Deviance             =  53.97790238               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0679252               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.440498   .0807947    17.83   0.000     1.282143    1.598853
         l_kijs25 |   2.235023   .0902539    24.76   0.000     2.058129    2.411917
            _cons |  -16.09173   .8088848   -19.89   0.000    -17.67711   -14.50634
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0039e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.64  P   
Iteration 2:   deviance = 7.8390e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.00      
Iteration 3:   deviance = 5.8096e+01  eps = 3.49e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.44      
Iteration 4:   deviance = 5.4790e+01  eps = 6.03e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.59      
Iteration 5:   deviance = 5.4495e+01  eps = 5.42e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.38      
Iteration 6:   deviance = 5.4483e+01  eps = 2.11e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.86      
Iteration 7:   deviance = 5.4483e+01  eps = 3.44e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.01      
Iteration 8:   deviance = 5.4483e+01  eps = 1.04e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.02   S  
Iteration 9:   deviance = 5.4483e+01  eps = 2.15e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.02   S  
Iteration 10:  deviance = 5.4483e+01  eps = 1.35e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.02   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     737.22
Deviance             =  54.48290266               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.3204254               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.46118   .0808617    18.07   0.000     1.302694    1.619666
         l_kijs26 |   2.031948   .0863366    23.54   0.000     1.862731    2.201165
            _cons |  -15.41482   .8019383   -19.22   0.000    -16.98659   -13.84305
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9972e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7433e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.6829e+01  eps = 3.63e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.60      
Iteration 4:   deviance = 5.3451e+01  eps = 6.32e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.81      
Iteration 5:   deviance = 5.3150e+01  eps = 5.66e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.62      
Iteration 6:   deviance = 5.3138e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.10      
Iteration 7:   deviance = 5.3138e+01  eps = 3.61e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.26      
Iteration 8:   deviance = 5.3138e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.27   S  
Iteration 9:   deviance = 5.3138e+01  eps = 2.43e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.27   S  
Iteration 10:  deviance = 5.3138e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.27   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     844.98
Deviance             =   53.1382617               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6481049               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.401668   .0811181    17.28   0.000     1.242679    1.560657
         l_kijs27 |    2.72308   .1047104    26.01   0.000     2.517852    2.928309
            _cons |  -15.56299   .8097621   -19.22   0.000     -17.1501   -13.97589
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9989e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7688e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.7171e+01  eps = 3.59e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.55      
Iteration 4:   deviance = 5.3813e+01  eps = 6.24e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.74      
Iteration 5:   deviance = 5.3513e+01  eps = 5.59e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.54      
Iteration 6:   deviance = 5.3502e+01  eps = 2.18e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.02      
Iteration 7:   deviance = 5.3502e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.18      
Iteration 8:   deviance = 5.3502e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.19   S  
Iteration 9:   deviance = 5.3502e+01  eps = 2.33e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.19   S  
Iteration 10:  deviance = 5.3502e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.19   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     825.05
Deviance             =  53.50155683               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8297525               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.420232   .0809758    17.54   0.000     1.261522    1.578942
         l_kijs28 |   2.510926   .0983586    25.53   0.000     2.318147    2.703706
            _cons |  -15.86899   .8097906   -19.60   0.000    -17.45615   -14.28183
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0023e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8155e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.7785e+01  eps = 3.53e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.50      
Iteration 4:   deviance = 5.4461e+01  eps = 6.10e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.67      
Iteration 5:   deviance = 5.4164e+01  eps = 5.48e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.47      
Iteration 6:   deviance = 5.4153e+01  eps = 2.13e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.94      
Iteration 7:   deviance = 5.4152e+01  eps = 3.48e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.10      
Iteration 8:   deviance = 5.4152e+01  eps = 1.05e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.11   S  
Iteration 9:   deviance = 5.4152e+01  eps = 2.23e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.11   S  
Iteration 10:  deviance = 5.4152e+01  eps = 1.36e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.11   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     756.95
Deviance             =  54.15242223               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.1551852               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.449454   .0810944    17.87   0.000     1.290512    1.608396
         l_kijs29 |   2.263253   .0940966    24.05   0.000     2.078827    2.447679
            _cons |  -14.90021   .8009586   -18.60   0.000    -16.47006   -13.33036
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0013e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8030e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.7622e+01  eps = 3.54e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.49      
Iteration 4:   deviance = 5.4290e+01  eps = 6.14e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.67      
Iteration 5:   deviance = 5.3993e+01  eps = 5.51e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.47      
Iteration 6:   deviance = 5.3981e+01  eps = 2.14e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.94      
Iteration 7:   deviance = 5.3981e+01  eps = 3.50e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.10      
Iteration 8:   deviance = 5.3981e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.11   S  
Iteration 9:   deviance = 5.3981e+01  eps = 2.24e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.11   S  
Iteration 10:  deviance = 5.3981e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.11   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     783.18
Deviance             =   53.9807703               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0693592               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.44178   .0809408    17.81   0.000     1.283139    1.600421
         l_kijs30 |   2.280469   .0926719    24.61   0.000     2.098835    2.462102
            _cons |   -15.6302   .8060631   -19.39   0.000    -17.21005   -14.05035
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9972e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7430e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.6826e+01  eps = 3.63e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.60      
Iteration 4:   deviance = 5.3449e+01  eps = 6.32e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.81      
Iteration 5:   deviance = 5.3148e+01  eps = 5.66e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.61      
Iteration 6:   deviance = 5.3136e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.09      
Iteration 7:   deviance = 5.3136e+01  eps = 3.60e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.25      
Iteration 8:   deviance = 5.3136e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.27   S  
Iteration 9:   deviance = 5.3136e+01  eps = 2.43e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.27   S  
Iteration 10:  deviance = 5.3136e+01  eps = 1.38e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.27   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     848.55
Deviance             =    53.136076               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6470121               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.401656    .081077    17.29   0.000     1.242748    1.560564
         l_kijs31 |   2.710303   .1039768    26.07   0.000     2.506512    2.914094
            _cons |  -15.72499   .8106524   -19.40   0.000    -17.31384   -14.13614
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9950e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.7128e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.11      
Iteration 3:   deviance = 5.6431e+01  eps = 3.67e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.63      
Iteration 4:   deviance = 5.3032e+01  eps = 6.41e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.85      
Iteration 5:   deviance = 5.2730e+01  eps = 5.73e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.66      
Iteration 6:   deviance = 5.2718e+01  eps = 2.24e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.14      
Iteration 7:   deviance = 5.2718e+01  eps = 3.66e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.30      
Iteration 8:   deviance = 5.2718e+01  eps = 1.12e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.32   S  
Iteration 9:   deviance = 5.2718e+01  eps = 2.52e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.32   S  
Iteration 10:  deviance = 5.2718e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.32   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     889.09
Deviance             =  52.71791647               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.4379323               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.377543   .0809763    17.01   0.000     1.218832    1.536254
         l_kijs32 |   2.867267   .1065822    26.90   0.000      2.65837    3.076164
            _cons |  -16.27837   .8155524   -19.96   0.000    -17.87682   -14.67991
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9983e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7591e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.7040e+01  eps = 3.60e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.57      
Iteration 4:   deviance = 5.3674e+01  eps = 6.27e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3374e+01  eps = 5.62e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.58      
Iteration 6:   deviance = 5.3362e+01  eps = 2.19e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 7:   deviance = 5.3362e+01  eps = 3.58e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.3362e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.23   S  
Iteration 9:   deviance = 5.3362e+01  eps = 2.37e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.23   S  
Iteration 10:  deviance = 5.3362e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.23   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     828.87
Deviance             =  53.36196112               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7599546               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.413552     .08109    17.43   0.000     1.254619    1.572486
         l_kijs33 |   2.612192   .1018556    25.65   0.000     2.412558    2.811825
            _cons |  -15.55114   .8086703   -19.23   0.000    -17.13611   -13.96618
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9952e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.7140e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.12      
Iteration 3:   deviance = 5.6444e+01  eps = 3.67e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.64      
Iteration 4:   deviance = 5.3045e+01  eps = 6.41e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.86      
Iteration 5:   deviance = 5.2743e+01  eps = 5.73e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.67      
Iteration 6:   deviance = 5.2731e+01  eps = 2.24e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.16      
Iteration 7:   deviance = 5.2731e+01  eps = 3.66e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.32      
Iteration 8:   deviance = 5.2731e+01  eps = 1.12e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.33   S  
Iteration 9:   deviance = 5.2731e+01  eps = 2.53e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.33   S  
Iteration 10:  deviance = 5.2731e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.33   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     880.85
Deviance             =  52.73123456               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.4445913               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.378085   .0810574    17.00   0.000     1.219215    1.536955
         l_kijs34 |   2.885284   .1077936    26.77   0.000     2.674012    3.096556
            _cons |  -15.96459   .8137535   -19.62   0.000    -17.55952   -14.36966
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0035e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.64  P   
Iteration 2:   deviance = 7.8324e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.01      
Iteration 3:   deviance = 5.8009e+01  eps = 3.50e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.45      
Iteration 4:   deviance = 5.4698e+01  eps = 6.05e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.61      
Iteration 5:   deviance = 5.4402e+01  eps = 5.44e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.40      
Iteration 6:   deviance = 5.4391e+01  eps = 2.12e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.88      
Iteration 7:   deviance = 5.4390e+01  eps = 3.45e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.03      
Iteration 8:   deviance = 5.4390e+01  eps = 1.04e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.04   S  
Iteration 9:   deviance = 5.4390e+01  eps = 2.17e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.04   S  
Iteration 10:  deviance = 5.4390e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.04   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     744.24
Deviance             =  54.39044715               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.2741976               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.458057   .0809107    18.02   0.000     1.299475    1.616639
         l_kijs35 |   2.089382   .0881125    23.71   0.000     1.916684    2.262079
            _cons |  -15.34586   .8020727   -19.13   0.000    -16.91789   -13.77383
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9986e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7623e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.7080e+01  eps = 3.60e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.58      
Iteration 4:   deviance = 5.3716e+01  eps = 6.26e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3417e+01  eps = 5.61e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.59      
Iteration 6:   deviance = 5.3405e+01  eps = 2.19e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 7:   deviance = 5.3405e+01  eps = 3.57e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.3405e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.24   S  
Iteration 9:   deviance = 5.3405e+01  eps = 2.38e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.24   S  
Iteration 10:  deviance = 5.3405e+01  eps = 1.37e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.24   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     819.87
Deviance             =  53.40468944               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7813188               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.415579   .0811582    17.44   0.000     1.256512    1.574646
         l_kijs36 |   2.617442   .1027505    25.47   0.000     2.416055    2.818829
            _cons |  -15.25237   .8068584   -18.90   0.000    -16.83378   -13.67096
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0058e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8608e+01  eps = 1.55e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.01      
Iteration 3:   deviance = 5.8377e+01  eps = 3.47e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.46      
Iteration 4:   deviance = 5.5085e+01  eps = 5.98e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.61      
Iteration 5:   deviance = 5.4791e+01  eps = 5.38e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.40      
Iteration 6:   deviance = 5.4779e+01  eps = 2.10e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.88      
Iteration 7:   deviance = 5.4779e+01  eps = 3.42e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.03      
Iteration 8:   deviance = 5.4779e+01  eps = 1.03e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.04   S  
Iteration 9:   deviance = 5.4779e+01  eps = 2.14e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.04   S  
Iteration 10:  deviance = 5.4779e+01  eps = 1.34e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.04   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     690.44
Deviance             =   54.7790552               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.4685017               Pseudo R2       =     0.6331
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.471449   .0811123    18.14   0.000     1.312472    1.630427
         l_kijs37 |   2.047762   .0912641    22.44   0.000     1.868887    2.226636
            _cons |  -13.79503   .7912241   -17.44   0.000    -15.34581   -12.24426
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9983e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7595e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.7044e+01  eps = 3.60e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.58      
Iteration 4:   deviance = 5.3679e+01  eps = 6.27e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3379e+01  eps = 5.62e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.58      
Iteration 6:   deviance = 5.3367e+01  eps = 2.19e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 7:   deviance = 5.3367e+01  eps = 3.58e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.3367e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.23   S  
Iteration 9:   deviance = 5.3367e+01  eps = 2.38e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.23   S  
Iteration 10:  deviance = 5.3367e+01  eps = 1.38e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.23   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     827.95
Deviance             =  53.36703473               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7624914               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.413807   .0810963    17.43   0.000     1.254861    1.572753
         l_kijs38 |   2.612067   .1019209    25.63   0.000     2.412306    2.811828
            _cons |  -15.52398   .8084985   -19.20   0.000    -17.10861   -13.93935
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0038e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8355e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.02      
Iteration 3:   deviance = 5.8048e+01  eps = 3.50e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.47      
Iteration 4:   deviance = 5.4738e+01  eps = 6.05e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.64      
Iteration 5:   deviance = 5.4443e+01  eps = 5.43e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.43      
Iteration 6:   deviance = 5.4431e+01  eps = 2.12e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.91      
Iteration 7:   deviance = 5.4431e+01  eps = 3.45e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 8:   deviance = 5.4431e+01  eps = 1.04e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.07   S  
Iteration 9:   deviance = 5.4431e+01  eps = 2.18e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.08   S  
Iteration 10:  deviance = 5.4431e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.08   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     728.71
Deviance             =  54.43107689               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.2945125               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.460125   .0811012    18.00   0.000      1.30117    1.619081
         l_kijs39 |   2.154034   .0920973    23.39   0.000     1.973527    2.334542
            _cons |  -14.52783   .7972167   -18.22   0.000    -16.09035   -12.96531
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9997e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7788e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.7299e+01  eps = 3.58e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.55      
Iteration 4:   deviance = 5.3948e+01  eps = 6.21e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.74      
Iteration 5:   deviance = 5.3649e+01  eps = 5.57e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.54      
Iteration 6:   deviance = 5.3638e+01  eps = 2.17e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.02      
Iteration 7:   deviance = 5.3638e+01  eps = 3.54e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.18      
Iteration 8:   deviance = 5.3638e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.19   S  
Iteration 9:   deviance = 5.3638e+01  eps = 2.32e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.19   S  
Iteration 10:  deviance = 5.3638e+01  eps = 1.37e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.19   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     804.41
Deviance             =  53.63751178               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8977299               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.427033   .0810982    17.60   0.000     1.268083    1.585982
         l_kijs40 |    2.49044   .0991531    25.12   0.000     2.296103    2.684777
            _cons |  -15.33765   .8061685   -19.03   0.000    -16.91772   -13.75759
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9966e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7373e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.6757e+01  eps = 3.63e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.59      
Iteration 4:   deviance = 5.3376e+01  eps = 6.33e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.79      
Iteration 5:   deviance = 5.3075e+01  eps = 5.67e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.60      
Iteration 6:   deviance = 5.3063e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.08      
Iteration 7:   deviance = 5.3063e+01  eps = 3.61e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.24      
Iteration 8:   deviance = 5.3063e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.25   S  
Iteration 9:   deviance = 5.3063e+01  eps = 2.42e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.25   S  
Iteration 10:  deviance = 5.3063e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.25   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     868.15
Deviance             =  53.06292316               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6104356               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.397346   .0808994    17.27   0.000     1.238786    1.555906
         l_kijs41 |   2.690282   .1018407    26.42   0.000     2.490677    2.889886
            _cons |  -16.37744   .8146063   -20.10   0.000    -17.97404   -14.78084
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0029e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8231e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.7883e+01  eps = 3.52e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.49      
Iteration 4:   deviance = 5.4565e+01  eps = 6.08e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.67      
Iteration 5:   deviance = 5.4268e+01  eps = 5.46e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.46      
Iteration 6:   deviance = 5.4257e+01  eps = 2.13e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.94      
Iteration 7:   deviance = 5.4257e+01  eps = 3.47e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.09      
Iteration 8:   deviance = 5.4257e+01  eps = 1.05e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.10   S  
Iteration 9:   deviance = 5.4257e+01  eps = 2.21e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.10   S  
Iteration 10:  deviance = 5.4257e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.10   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     744.63
Deviance             =   54.2565588               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.2072535               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.453535   .0811255    17.92   0.000     1.294532    1.612538
         l_kijs42 |   2.234365   .0939875    23.77   0.000     2.050152    2.418577
            _cons |  -14.64399   .7989577   -18.33   0.000    -16.20992   -13.07806
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0000e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7799e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.7306e+01  eps = 3.58e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.58      
Iteration 4:   deviance = 5.3954e+01  eps = 6.21e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3656e+01  eps = 5.57e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.58      
Iteration 6:   deviance = 5.3644e+01  eps = 2.17e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 7:   deviance = 5.3644e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.3644e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.23   S  
Iteration 9:   deviance = 5.3644e+01  eps = 2.35e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.23   S  
Iteration 10:  deviance = 5.3644e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.23   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     788.14
Deviance             =  53.64368533               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.9008167               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.426134   .0812877    17.54   0.000     1.266813    1.585455
         l_kijs43 |   2.569723   .1035602    24.81   0.000     2.366749    2.772698
            _cons |  -14.44715   .8015584   -18.02   0.000    -16.01818   -12.87613
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0012e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7959e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.06      
Iteration 3:   deviance = 5.7519e+01  eps = 3.55e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.55      
Iteration 4:   deviance = 5.4180e+01  eps = 6.16e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.75      
Iteration 5:   deviance = 5.3882e+01  eps = 5.53e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.55      
Iteration 6:   deviance = 5.3870e+01  eps = 2.16e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.02      
Iteration 7:   deviance = 5.3870e+01  eps = 3.53e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.18      
Iteration 8:   deviance = 5.3870e+01  eps = 1.07e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.19   S  
Iteration 9:   deviance = 5.3870e+01  eps = 2.30e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.19   S  
Iteration 10:  deviance = 5.3870e+01  eps = 1.36e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.19   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     769.25
Deviance             =  53.87000576               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0139769               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.436592   .0812756    17.68   0.000     1.277295    1.595889
         l_kijs44 |   2.468531   .1012474    24.38   0.000      2.27009    2.666972
            _cons |   -14.3053   .7996327   -17.89   0.000    -15.87255   -12.73805
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0059e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.64  P   
Iteration 2:   deviance = 7.8644e+01  eps = 1.55e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.00      
Iteration 3:   deviance = 5.8427e+01  eps = 3.46e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.43      
Iteration 4:   deviance = 5.5139e+01  eps = 5.96e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.58      
Iteration 5:   deviance = 5.4845e+01  eps = 5.36e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.37      
Iteration 6:   deviance = 5.4833e+01  eps = 2.09e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.84      
Iteration 7:   deviance = 5.4833e+01  eps = 3.41e-06  iters = 2    tol = 1.0e-04  min(eta) =  -8.99      
Iteration 8:   deviance = 5.4833e+01  eps = 1.03e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.01   S  
Iteration 9:   deviance = 5.4833e+01  eps = 2.12e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.01   S  
Iteration 10:  deviance = 5.4833e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.01   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     691.78
Deviance             =  54.83317457               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.4955613               Pseudo R2       =     0.6331
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.473878   .0810039    18.20   0.000     1.315114    1.632643
         l_kijs45 |    1.96035   .0873273    22.45   0.000     1.789192    2.131509
            _cons |  -14.34018   .7933695   -18.08   0.000    -15.89515    -12.7852
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9983e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.7536e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.11      
Iteration 3:   deviance = 5.6956e+01  eps = 3.61e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.62      
Iteration 4:   deviance = 5.3584e+01  eps = 6.29e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.84      
Iteration 5:   deviance = 5.3283e+01  eps = 5.64e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.64      
Iteration 6:   deviance = 5.3271e+01  eps = 2.20e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.13      
Iteration 7:   deviance = 5.3271e+01  eps = 3.60e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.29      
Iteration 8:   deviance = 5.3271e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.30   S  
Iteration 9:   deviance = 5.3271e+01  eps = 2.44e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.30   S  
Iteration 10:  deviance = 5.3271e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.30   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     814.22
Deviance             =  53.27113619               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7145422               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.406149   .0813243    17.29   0.000     1.246757    1.565542
         l_kijs46 |   2.751997   .1082615    25.42   0.000     2.539809    2.964186
            _cons |  -14.43569   .8033401   -17.97   0.000    -16.01021   -12.86118
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0008e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.7954e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7521e+01  eps = 3.55e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.51      
Iteration 4:   deviance = 5.4183e+01  eps = 6.16e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.70      
Iteration 5:   deviance = 5.3885e+01  eps = 5.53e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.49      
Iteration 6:   deviance = 5.3873e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.97      
Iteration 7:   deviance = 5.3873e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.12      
Iteration 8:   deviance = 5.3873e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.14   S  
Iteration 9:   deviance = 5.3873e+01  eps = 2.27e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.14   S  
Iteration 10:  deviance = 5.3873e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.14   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     788.67
Deviance             =  53.87299961               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0154739               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.437518   .0810158    17.74   0.000      1.27873    1.596306
         l_kijs47 |   2.354926   .0951535    24.75   0.000     2.168428    2.541423
            _cons |  -15.46081   .8056437   -19.19   0.000    -17.03984   -13.88178
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9989e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7660e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.7129e+01  eps = 3.59e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.58      
Iteration 4:   deviance = 5.3768e+01  eps = 6.25e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3468e+01  eps = 5.60e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.58      
Iteration 6:   deviance = 5.3457e+01  eps = 2.18e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 7:   deviance = 5.3456e+01  eps = 3.57e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.3456e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.23   S  
Iteration 9:   deviance = 5.3456e+01  eps = 2.37e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.23   S  
Iteration 10:  deviance = 5.3456e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.23   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     814.96
Deviance             =  53.45631569               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8071319               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.418149   .0811651    17.47   0.000     1.259068    1.577229
         l_kijs48 |   2.596914   .1023669    25.37   0.000     2.396278    2.797549
            _cons |   -15.1908   .8062814   -18.84   0.000    -16.77109   -13.61052
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9983e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.7548e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.09      
Iteration 3:   deviance = 5.6975e+01  eps = 3.61e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.61      
Iteration 4:   deviance = 5.3605e+01  eps = 6.29e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.82      
Iteration 5:   deviance = 5.3304e+01  eps = 5.63e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.63      
Iteration 6:   deviance = 5.3293e+01  eps = 2.20e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.11      
Iteration 7:   deviance = 5.3293e+01  eps = 3.60e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.27      
Iteration 8:   deviance = 5.3293e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.28   S  
Iteration 9:   deviance = 5.3293e+01  eps = 2.42e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.28   S  
Iteration 10:  deviance = 5.3293e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.28   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     818.40
Deviance             =  53.29250843               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7252283               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.408575   .0812742    17.33   0.000      1.24928    1.567869
         l_kijs49 |   2.716079   .1065662    25.49   0.000     2.507213    2.924945
            _cons |  -14.75268   .8048123   -18.33   0.000    -16.33009   -13.17528
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0002e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7818e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.7332e+01  eps = 3.57e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.58      
Iteration 4:   deviance = 5.3981e+01  eps = 6.21e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3682e+01  eps = 5.57e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.58      
Iteration 6:   deviance = 5.3671e+01  eps = 2.17e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 7:   deviance = 5.3671e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.3671e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.23   S  
Iteration 9:   deviance = 5.3671e+01  eps = 2.35e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.23   S  
Iteration 10:  deviance = 5.3671e+01  eps = 1.37e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.23   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     784.65
Deviance             =  53.67053729               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.9142427               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.427188   .0812992    17.55   0.000     1.267844    1.586531
         l_kijs50 |   2.564765   .1036735    24.74   0.000     2.361568    2.767961
            _cons |  -14.35292   .8009656   -17.92   0.000    -15.92279   -12.78306
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+

. 
. clear

. svmat coef_gravity
number of observations will be reset to 50
Press any key to continue, or Break to abort
number of observations (_N) was 0, now 50

. 
. save "$folder\Cleaned Data\coef_gravity.dta",replace
file D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\coef_gravity.dta s
> aved

. 
end of do-file

. sum

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
coef_gravi~1 |         50     1.42871    .0233052   1.377543   1.473879
coef_gravi~2 |         50     2.46173    .2330122    1.96035   2.885284
coef_gravi~3 |         50   -15.15619    .6183199  -16.37744  -13.79503

. do "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity E
> quation\03.Solving_Model.do"

. ***** Solving the Model                   *********
. ***** Zibin Huang 2019.12.20      *********
. 
. ***********************************************************************
. * Load Cleaned Migration Flow Data from Census 2010
. ***********************************************************************
. 
. clear

. set more off

. clear matrix

. clear mata

. 
. global folder "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model"

. cd "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity E
> quation"
D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity Equatio
> n

. 
. use "$folder\Cleaned Data\data_for_gravity.dta",clear

. 
. ***********************************************************************
. * Setting Parameters (Derived from previous steps)
. ***********************************************************************
. local sigma=3

. local epsilon=1.43

. local beta=1.72

. 
. ***********************************************************************
. * Local Productivity
. ***********************************************************************
. egen living_skill=group(living_city college)

. bysort living_skill: egen resident_living=sum(mig_perturb)

. label var resident_living "Number of residents living in this city with this skill"

. bysort hukou_skill: egen resident_hukou=sum(mig_perturb)

. label var resident_hukou "Number of residents having Hukou of this city with this skill"

. 
. gen num_commuting=pi_ijs*resident_hukou

. 
. gen liv_num_local_stu_i=liv_local_family_city_low+liv_local_family_city_high

. gen liv_num_mig_stu_j=liv_mig_family_city_low+liv_mig_family_city_high

. gen liv_num_lb_stu_i=liv_left_family_city_low+liv_left_family_city_high

. gen liv_num_local_stu_i_high=liv_local_family_city_high

. gen liv_num_local_stu_i_low=liv_local_family_city_low

. gen liv_num_mig_stu_j_high=liv_mig_family_city_high

. gen liv_num_mig_stu_j_low=liv_mig_family_city_low

. gen liv_num_lb_stu_i_high=liv_left_family_city_high

. gen liv_num_lb_stu_i_low=liv_left_family_city_low

. 
. gen hk_num_local_stu_i=hk_local_family_city_low+hk_local_family_city_high

. gen hk_num_mig_stu_j=hk_mig_family_city_low+hk_mig_family_city_high

. gen hk_num_lb_stu_i=hk_left_family_city_low+hk_left_family_city_high

. gen hk_num_local_stu_i_high=hk_local_family_city_high

. gen hk_num_local_stu_i_low=hk_local_family_city_low

. gen hk_num_mig_stu_j_high=hk_mig_family_city_high

. gen hk_num_mig_stu_j_low=hk_mig_family_city_low

. gen hk_num_lb_stu_i_high=hk_left_family_city_high

. gen hk_num_lb_stu_i_low=hk_left_family_city_low

. 
. gen wage_high=city_skill_wage if college==1
(80,656 missing values generated)

. label var wage_high "High skill wage in this city"

. gen wage_low=city_skill_wage if college==0
(80,656 missing values generated)

. label var wage_low "Low skill wage in this city"

. gen living_resident_high=resident_living if college==1
(80,656 missing values generated)

. label var living_resident_high "High skill residents in this city"

. gen living_resident_low=resident_living if college==0
(80,656 missing values generated)

. label var living_resident_low "Low skill residents in this city"

. gen hukou_resident_high=resident_hukou if college==1
(80,656 missing values generated)

. label var hukou_resident_high "High skill Hukou holder of this city"

. gen hukou_resident_low=resident_hukou if college==0
(80,656 missing values generated)

. label var hukou_resident_low "Low skill Hukou holder of this city"

. xfill wage_high wage_low living_resident_high living_resident_low,i(living_city_num)

. xfill hukou_resident_high hukou_resident_low,i(hukou_city_num)

. 
. 
. /* Asj is the local productivity for workers with skill s in city j */
. gen temp=(wage_low*living_resident_low)/(wage_high*living_resident_high)

. gen Asj=city_skill_wage/((1+temp)^(1/(`sigma'-1))) if college==1
(80,656 missing values generated)

. replace Asj=city_skill_wage/((1+1/temp)^(1/(`sigma'-1))) if college==0
(80,656 real changes made)

. label var Asj "Productivity of this skill labor in this city"

. 
. gen A_high_j=Asj if college==1
(80,656 missing values generated)

. label var A_high_j "High skill productivity in this city"

. gen A_low_j=Asj if college==0
(80,656 missing values generated)

. label var A_low_j "Low skill productivity in this city"

. xfill A_high_j A_low_j,i(living_city_num)

. 
. ***********************************************************************
. * Migration Cost
. ***********************************************************************
. replace pi_ijs=0.000000001 if pi_ijs==0                                                                            
>                                      /* Impute pi_ijs for city-pair with zero migrants */
(147,165 real changes made)

. gen phi_is=(city_skill_wage*kijs^`beta')^`epsilon'/pi_ijs if living_city==hukou_city                    /* Use stay
> ers to calculate living city constant in the gravity equation */
(160,744 missing values generated)

. xfill phi_is,i(hukou_skill)

. 
. /* tau_ijs is the migration cost for workers with skill s migrating from city i to city j */
. gen tau_ijs=city_skill_wage*kijs^`beta'/((pi_ijs*phi_is)^(1/`epsilon'))

. replace tau_ijs=1 if  living_city==hukou_city                                                                      
>                              /* There is no iceberg migration cost for stayers */
(27 real changes made)

. label var tau_ijs "Migration cost from city j to city i for people with skill s"

. 
. 
. drop temp

. 
. save "$folder\Cleaned Data\data_for_counterfactual.dta",replace
file D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\data_for_counterfa
> ctual.dta saved

. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
end of do-file

. do "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity E
> quation\02.Gravity_Estimation_2010_het_skill.do"

. ***** Estimating Gravity Equation *********
. ***** Data: China Census 2010     *********
. ***** Zibin Huang 2020.2.19       *********
. ***** Heterogeneous in skills     *********
. 
. 
. ***********************************************************************
. * Load Cleaned Migration Flow Data from Census 2010
. ***********************************************************************
. 
. clear

. set more off

. clear matrix

. clear mata

. 
. /*
> cap ado uninstall ftools     /* Install package for high dimensional fixed effect regression */
> cap ado uninstall reghdfe
> cap ado uninstall ppmlhdfe
> 
> ssc install ftools
> ssc install reghdfe
> ssc install ppmlhdfe
> 
> clear all
> ftools, compile
> reghdfe, compile
> */
. 
. 
. global folder "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model"

. cd "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity E
> quation"
D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity Equatio
> n

. 
. import delimited "$folder\Cleaned Data\gravity_het_skill.csv",clear
(185 vars, 161,312 obs)

. 
. tostring living_city hukou_city,replace
living_city was int now str4
hukou_city was int now str4

. 
. merge m:1 living_city college using "$folder\Cleaned Data\city_skill_wage_2010_2005imputed.dta"
(note: variable college was byte, now float to accommodate using data's values)

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                           161,312  (_merge==3)
    -----------------------------------------

. *merge m:1 living_city college using "$folder\Cleaned Data\2010_wage_city_skill.dta"
. drop _merge

. 
. *keep hukou_city hukou_city_num living_city living_city_num city_pair college mig city_skill_wage expected_outmig_u
>  expected_stay_u
. 
. /*
> /* Calculate Overall Migration Rate */
> egen total_people=sum(mig)
> egen total_stayer=sum(mig) if living_city==hukou_city                   /* Number of stayers */
> gen x=1
> xfill total_stayer,i(x)
> drop x
> */
. 
. replace city_skill_wage=imputed_city_skill_wage_2010
(161,312 real changes made)

. 
. save "$folder\Cleaned Data\data_for_gravity_het_skill.dta",replace
file D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\data_for_gravity_h
> et_skill.dta saved

. 
. 
. ***********************************************************************
. * Generate Variables in Regression
. ***********************************************************************
. 
. *-- Wage
. gen l_city_skill_wage=log(city_skill_wage)

. 
. *-- Migration flows
. gen mig_perturb=mig

. replace mig_perturb=0 if mig==0                         /* If migration flow is zero, assign a very small number be
> fore taking log */
(0 real changes made)

. gen l_mig_perturb=log(mig_perturb)
(147,165 missing values generated)

. 
. egen hukou_skill=group(hukou_city college)

. bysort hukou_skill: egen mig_hukou=sum(mig_perturb)

. sort hukou_city living_city college

. gen pi_ijs = mig_perturb/mig_hukou

. gen l_pi_ijs=log(pi_ijs)
(147,165 missing values generated)

. 
. *-- Human capital
. *gen kijs_star=expected_outmig_u if living_city!=hukou_city
. *replace kijs_star=expected_stay_u if living_city==hukou_city
. *sum kijs
. *replace kijs=kijs+1.4                                  /* Normalizing kijs to be positive */
. *gen kijs=exp(kijs_star)
. *gen l_kijs=log(kijs)
. 
. *-- Fixed effects
. egen feij=group(city_pair)

. egen feis=group(hukou_city college)

. egen fejs=group(living_city college)

. 
. gen weight=mig+1

. 
. save "$folder\Cleaned Data\data_for_gravity_het_skill.dta",replace
file D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\data_for_gravity_h
> et_skill.dta saved

. 
. 
. ***********************************************************************
. * Gravity Equation Estimation
. ***********************************************************************
. *mat coef_gravity
. forvalues i=1(1)50{
  2.         ppmlhdfe pi_ijs l_city_skill_wage l_kijs`i',absorb(feij feis) vce(r)                                    
>                 /* A gravity equation with fixed effects on original city-destination city level and original city-
> skill level */
  3.         *outreg2 using Gravity,tex replace keep(l_city_skill_wage l_kijs) ctitle(1) addtext(Original-Destination
>  City Fixed Effects, YES, Original City-Skill Fixed Effects, YES)
.         if `i'==1{
  4.         mat coef_gravity=e(b)
  5.         }
  6.         else{
  7.         mat a=e(b)
  8.         mat coef_gravity=[coef_gravity \ a]
  9.         }
 10.         *testnl _b[l_kijs]/_b[l_city_skill_wage]=0
. }
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9935e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7057e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.6445e+01  eps = 3.65e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.58      
Iteration 4:   deviance = 5.3076e+01  eps = 6.35e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.2776e+01  eps = 5.69e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.58      
Iteration 6:   deviance = 5.2764e+01  eps = 2.22e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 7:   deviance = 5.2764e+01  eps = 3.64e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.2764e+01  eps = 1.11e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.23   S  
Iteration 9:   deviance = 5.2764e+01  eps = 2.45e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.23   S  
Iteration 10:  deviance = 5.2764e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.23   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     889.96
Deviance             =  52.76421667               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.4610824               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.399709   .0810371    17.27   0.000     1.240879    1.558539
          l_kijs1 |   2.525885   .0941305    26.83   0.000     2.341393    2.710377
            _cons |  -14.37141   .8007638   -17.95   0.000    -15.94088   -12.80194
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0007e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.7933e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7470e+01  eps = 3.56e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.52      
Iteration 4:   deviance = 5.4121e+01  eps = 6.19e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.71      
Iteration 5:   deviance = 5.3823e+01  eps = 5.54e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.51      
Iteration 6:   deviance = 5.3811e+01  eps = 2.16e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.99      
Iteration 7:   deviance = 5.3811e+01  eps = 3.52e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.15      
Iteration 8:   deviance = 5.3811e+01  eps = 1.07e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.16   S  
Iteration 9:   deviance = 5.3811e+01  eps = 2.29e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.16   S  
Iteration 10:  deviance = 5.3811e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.16   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     800.54
Deviance             =  53.81115054               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.9845493               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.429194   .0807135    17.71   0.000     1.270999     1.58739
          l_kijs2 |   2.442472   .0978966    24.95   0.000     2.250598    2.634345
            _cons |  -15.49083   .8034494   -19.28   0.000    -17.06556    -13.9161
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9948e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.7146e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.10      
Iteration 3:   deviance = 5.6492e+01  eps = 3.66e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.61      
Iteration 4:   deviance = 5.3107e+01  eps = 6.37e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.82      
Iteration 5:   deviance = 5.2805e+01  eps = 5.71e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.63      
Iteration 6:   deviance = 5.2794e+01  eps = 2.23e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.11      
Iteration 7:   deviance = 5.2794e+01  eps = 3.64e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.27      
Iteration 8:   deviance = 5.2794e+01  eps = 1.12e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.28   S  
Iteration 9:   deviance = 5.2794e+01  eps = 2.48e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.28   S  
Iteration 10:  deviance = 5.2794e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.28   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     882.75
Deviance             =  52.79350025               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.4757242               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.389895   .0810758    17.14   0.000     1.230989      1.5488
          l_kijs3 |   2.729258   .1019903    26.76   0.000     2.529361    2.929155
            _cons |  -15.43637   .8088266   -19.08   0.000    -17.02164    -13.8511
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0048e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8423e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.8085e+01  eps = 3.50e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.51      
Iteration 4:   deviance = 5.4764e+01  eps = 6.07e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.70      
Iteration 5:   deviance = 5.4467e+01  eps = 5.45e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.49      
Iteration 6:   deviance = 5.4456e+01  eps = 2.12e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.97      
Iteration 7:   deviance = 5.4455e+01  eps = 3.46e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.12      
Iteration 8:   deviance = 5.4455e+01  eps = 1.05e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.14   S  
Iteration 9:   deviance = 5.4455e+01  eps = 2.22e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.14   S  
Iteration 10:  deviance = 5.4455e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.14   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     715.66
Deviance             =  54.45548377               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.3067159               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.450796     .08111    17.89   0.000     1.291823    1.609768
          l_kijs4 |   2.367955   .1022178    23.17   0.000     2.167612    2.568298
            _cons |  -14.74086   .7995279   -18.44   0.000    -16.30791   -13.17382
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9934e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.6947e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.12      
Iteration 3:   deviance = 5.6227e+01  eps = 3.69e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.64      
Iteration 4:   deviance = 5.2826e+01  eps = 6.44e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.86      
Iteration 5:   deviance = 5.2524e+01  eps = 5.76e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.67      
Iteration 6:   deviance = 5.2512e+01  eps = 2.25e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.15      
Iteration 7:   deviance = 5.2512e+01  eps = 3.68e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.31      
Iteration 8:   deviance = 5.2512e+01  eps = 1.13e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.32   S  
Iteration 9:   deviance = 5.2512e+01  eps = 2.56e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.32   S  
Iteration 10:  deviance = 5.2512e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.32   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     908.45
Deviance             =  52.51180888               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.3348785               Pseudo R2       =     0.6336
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.370892   .0808279    16.96   0.000     1.212473    1.529312
          l_kijs5 |   2.838804    .104111    27.27   0.000      2.63475    3.042858
            _cons |  -15.21417   .8057653   -18.88   0.000    -16.79344    -13.6349
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0037e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.8254e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.7846e+01  eps = 3.53e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.55      
Iteration 4:   deviance = 5.4506e+01  eps = 6.13e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.74      
Iteration 5:   deviance = 5.4208e+01  eps = 5.50e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.54      
Iteration 6:   deviance = 5.4196e+01  eps = 2.14e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.02      
Iteration 7:   deviance = 5.4196e+01  eps = 3.49e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.18      
Iteration 8:   deviance = 5.4196e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.19   S  
Iteration 9:   deviance = 5.4196e+01  eps = 2.27e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.19   S  
Iteration 10:  deviance = 5.4196e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.19   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     739.60
Deviance             =  54.19571779               Prob > chi2     =     0.0000
Log pseudolikelihood =  -959.176833               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.437519   .0810167    17.74   0.000     1.278729    1.596309
          l_kijs6 |   2.534783   .1068533    23.72   0.000     2.325354    2.744212
            _cons |  -14.92163    .801269   -18.62   0.000    -16.49209   -13.35117
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9979e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7512e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.6904e+01  eps = 3.62e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.60      
Iteration 4:   deviance = 5.3520e+01  eps = 6.32e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.82      
Iteration 5:   deviance = 5.3219e+01  eps = 5.66e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.63      
Iteration 6:   deviance = 5.3207e+01  eps = 2.20e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.11      
Iteration 7:   deviance = 5.3207e+01  eps = 3.60e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.27      
Iteration 8:   deviance = 5.3207e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.28   S  
Iteration 9:   deviance = 5.3207e+01  eps = 2.43e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.28   S  
Iteration 10:  deviance = 5.3207e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.28   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     843.36
Deviance             =  53.20722517               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6825866               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.398705   .0808571    17.30   0.000     1.240228    1.557182
          l_kijs7 |    2.77153   .1069006    25.93   0.000     2.562009    2.981052
            _cons |  -15.58399   .8075244   -19.30   0.000    -17.16671   -14.00127
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9934e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7121e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.6607e+01  eps = 3.62e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.52      
Iteration 4:   deviance = 5.3267e+01  eps = 6.27e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.70      
Iteration 5:   deviance = 5.2969e+01  eps = 5.63e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.50      
Iteration 6:   deviance = 5.2957e+01  eps = 2.20e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.97      
Iteration 7:   deviance = 5.2957e+01  eps = 3.60e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.13      
Iteration 8:   deviance = 5.2957e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.14   S  
Iteration 9:   deviance = 5.2957e+01  eps = 2.36e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.14   S  
Iteration 10:  deviance = 5.2957e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.14   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     875.17
Deviance             =  52.95685714               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.5574026               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.421129   .0812858    17.48   0.000     1.261812    1.580446
          l_kijs8 |   2.226778    .084126    26.47   0.000     2.061894    2.391662
            _cons |  -13.99457   .8000221   -17.49   0.000    -15.56258   -12.42655
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9905e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.6621e+01  eps = 1.60e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.13      
Iteration 3:   deviance = 5.5853e+01  eps = 3.72e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.64      
Iteration 4:   deviance = 5.2447e+01  eps = 6.49e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.86      
Iteration 5:   deviance = 5.2144e+01  eps = 5.81e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.67      
Iteration 6:   deviance = 5.2132e+01  eps = 2.27e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.15      
Iteration 7:   deviance = 5.2132e+01  eps = 3.72e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.31      
Iteration 8:   deviance = 5.2132e+01  eps = 1.15e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.32   S  
Iteration 9:   deviance = 5.2132e+01  eps = 2.62e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.32   S  
Iteration 10:  deviance = 5.2132e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.32   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     949.59
Deviance             =  52.13204446               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.1449963               Pseudo R2       =     0.6336
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.354668    .080754    16.78   0.000     1.196393    1.512943
          l_kijs9 |   2.823405    .100552    28.08   0.000     2.626326    3.020483
            _cons |  -15.43229   .8073022   -19.12   0.000    -17.01457      -13.85
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0098e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.9029e+01  eps = 1.54e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.8789e+01  eps = 3.44e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.51      
Iteration 4:   deviance = 5.5475e+01  eps = 5.97e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.70      
Iteration 5:   deviance = 5.5178e+01  eps = 5.37e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.50      
Iteration 6:   deviance = 5.5167e+01  eps = 2.09e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.98      
Iteration 7:   deviance = 5.5167e+01  eps = 3.40e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.13      
Iteration 8:   deviance = 5.5167e+01  eps = 1.03e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.14   S  
Iteration 9:   deviance = 5.5167e+01  eps = 2.17e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.14   S  
Iteration 10:  deviance = 5.5167e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.14   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     643.36
Deviance             =  55.16680385               Prob > chi2     =     0.0000
Log pseudolikelihood =  -959.662376               Pseudo R2       =     0.6331
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.447172   .0804701    17.98   0.000     1.289454    1.604891
         l_kijs10 |   2.502204   .1173523    21.32   0.000     2.272198     2.73221
            _cons |  -14.93246   .7948155   -18.79   0.000    -16.49027   -13.37465
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0022e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8095e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7635e+01  eps = 3.55e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.53      
Iteration 4:   deviance = 5.4280e+01  eps = 6.18e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.72      
Iteration 5:   deviance = 5.3981e+01  eps = 5.54e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.52      
Iteration 6:   deviance = 5.3970e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.00      
Iteration 7:   deviance = 5.3970e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.15      
Iteration 8:   deviance = 5.3970e+01  eps = 1.07e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.17   S  
Iteration 9:   deviance = 5.3970e+01  eps = 2.28e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.17   S  
Iteration 10:  deviance = 5.3970e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.17   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     792.20
Deviance             =  53.96958203               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0637651               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.420538   .0803472    17.68   0.000      1.26306    1.578016
         l_kijs11 |   2.535471   .1025956    24.71   0.000     2.334388    2.736555
            _cons |  -16.21967   .8071453   -20.10   0.000    -17.80165    -14.6377
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0003e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.7906e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.7476e+01  eps = 3.55e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.50      
Iteration 4:   deviance = 5.4139e+01  eps = 6.16e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.68      
Iteration 5:   deviance = 5.3842e+01  eps = 5.53e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.48      
Iteration 6:   deviance = 5.3830e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.95      
Iteration 7:   deviance = 5.3830e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.11      
Iteration 8:   deviance = 5.3830e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.12   S  
Iteration 9:   deviance = 5.3830e+01  eps = 2.26e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.12   S  
Iteration 10:  deviance = 5.3830e+01  eps = 1.36e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.12   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     797.99
Deviance             =  53.82997297               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.9939605               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.43934   .0809086    17.79   0.000     1.280763    1.597918
         l_kijs12 |   2.293939   .0921385    24.90   0.000      2.11335    2.474527
            _cons |  -15.12015   .8016582   -18.86   0.000    -16.69137   -13.54893
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9920e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.6824e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.10      
Iteration 3:   deviance = 5.6102e+01  eps = 3.69e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.61      
Iteration 4:   deviance = 5.2704e+01  eps = 6.45e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.83      
Iteration 5:   deviance = 5.2402e+01  eps = 5.77e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.63      
Iteration 6:   deviance = 5.2390e+01  eps = 2.25e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.11      
Iteration 7:   deviance = 5.2390e+01  eps = 3.68e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.27      
Iteration 8:   deviance = 5.2390e+01  eps = 1.13e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.29   S  
Iteration 9:   deviance = 5.2390e+01  eps = 2.55e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.29   S  
Iteration 10:  deviance = 5.2390e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.29   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     936.43
Deviance             =  52.38976941               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.2738588               Pseudo R2       =     0.6336
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.369325   .0806724    16.97   0.000      1.21121     1.52744
         l_kijs13 |   2.746521   .0990037    27.74   0.000     2.552477    2.940564
            _cons |   -15.6017   .8068279   -19.34   0.000    -17.18305   -14.02034
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9974e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7542e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.06      
Iteration 3:   deviance = 5.7052e+01  eps = 3.59e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.55      
Iteration 4:   deviance = 5.3708e+01  eps = 6.23e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.74      
Iteration 5:   deviance = 5.3410e+01  eps = 5.59e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.54      
Iteration 6:   deviance = 5.3398e+01  eps = 2.18e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.01      
Iteration 7:   deviance = 5.3398e+01  eps = 3.57e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.17      
Iteration 8:   deviance = 5.3398e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.18   S  
Iteration 9:   deviance = 5.3398e+01  eps = 2.35e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.18   S  
Iteration 10:  deviance = 5.3398e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.18   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     823.03
Deviance             =  53.39802176               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7779849               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.428255   .0812812    17.57   0.000     1.268947    1.587564
         l_kijs14 |   2.388867   .0937688    25.48   0.000     2.205083     2.57265
            _cons |  -14.05063   .7993061   -17.58   0.000    -15.61724   -12.48401
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0005e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7893e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.7444e+01  eps = 3.56e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.54      
Iteration 4:   deviance = 5.4103e+01  eps = 6.18e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.73      
Iteration 5:   deviance = 5.3805e+01  eps = 5.54e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.53      
Iteration 6:   deviance = 5.3794e+01  eps = 2.16e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.01      
Iteration 7:   deviance = 5.3793e+01  eps = 3.53e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.17      
Iteration 8:   deviance = 5.3793e+01  eps = 1.07e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.18   S  
Iteration 9:   deviance = 5.3793e+01  eps = 2.30e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.18   S  
Iteration 10:  deviance = 5.3793e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.18   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     784.68
Deviance             =  53.79335632               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.9756522               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.43592   .0811354    17.70   0.000     1.276898    1.594943
         l_kijs15 |   2.429702   .0984653    24.68   0.000     2.236714    2.622691
            _cons |  -14.37954   .7989086   -18.00   0.000    -15.94537   -12.81371
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9983e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7559e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.6919e+01  eps = 3.63e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.60      
Iteration 4:   deviance = 5.3521e+01  eps = 6.35e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.82      
Iteration 5:   deviance = 5.3219e+01  eps = 5.68e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.63      
Iteration 6:   deviance = 5.3207e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.11      
Iteration 7:   deviance = 5.3207e+01  eps = 3.60e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.26      
Iteration 8:   deviance = 5.3207e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.28   S  
Iteration 9:   deviance = 5.3207e+01  eps = 2.45e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.28   S  
Iteration 10:  deviance = 5.3207e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.28   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     870.20
Deviance             =  53.20696256               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6824553               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.378298   .0800617    17.22   0.000      1.22138    1.535216
         l_kijs16 |   2.866536    .109132    26.27   0.000     2.652641    3.080431
            _cons |  -16.62506   .8093203   -20.54   0.000     -18.2113   -15.03882
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9949e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7157e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.09      
Iteration 3:   deviance = 5.6467e+01  eps = 3.66e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.61      
Iteration 4:   deviance = 5.3068e+01  eps = 6.41e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.83      
Iteration 5:   deviance = 5.2766e+01  eps = 5.73e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.64      
Iteration 6:   deviance = 5.2754e+01  eps = 2.23e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.12      
Iteration 7:   deviance = 5.2754e+01  eps = 3.65e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.28      
Iteration 8:   deviance = 5.2754e+01  eps = 1.12e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.29   S  
Iteration 9:   deviance = 5.2754e+01  eps = 2.51e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.29   S  
Iteration 10:  deviance = 5.2754e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.29   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     902.26
Deviance             =  52.75413021               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.4560392               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.376633    .080455    17.11   0.000     1.218944    1.534321
         l_kijs17 |   2.805771   .1038464    27.02   0.000     2.602236    3.009306
            _cons |  -15.68023   .8050374   -19.48   0.000    -17.25807   -14.10239
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9928e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7019e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.6428e+01  eps = 3.65e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.53      
Iteration 4:   deviance = 5.3065e+01  eps = 6.34e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.71      
Iteration 5:   deviance = 5.2766e+01  eps = 5.68e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.51      
Iteration 6:   deviance = 5.2754e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.99      
Iteration 7:   deviance = 5.2754e+01  eps = 3.62e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.14      
Iteration 8:   deviance = 5.2754e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.16   S  
Iteration 9:   deviance = 5.2754e+01  eps = 2.39e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.16   S  
Iteration 10:  deviance = 5.2754e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.16   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     917.21
Deviance             =  52.75374188               Prob > chi2     =     0.0000
Log pseudolikelihood =  -958.455845               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.405095   .0808655    17.38   0.000     1.246602    1.563589
         l_kijs18 |   2.346895    .086047    27.27   0.000     2.178246    2.515544
            _cons |   -15.5601   .8063033   -19.30   0.000    -17.14043   -13.97978
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9903e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.6681e+01  eps = 1.60e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.5990e+01  eps = 3.70e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.59      
Iteration 4:   deviance = 5.2606e+01  eps = 6.43e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.79      
Iteration 5:   deviance = 5.2304e+01  eps = 5.76e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.59      
Iteration 6:   deviance = 5.2293e+01  eps = 2.25e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 7:   deviance = 5.2292e+01  eps = 3.69e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.23      
Iteration 8:   deviance = 5.2292e+01  eps = 1.13e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.24   S  
Iteration 9:   deviance = 5.2292e+01  eps = 2.53e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.24   S  
Iteration 10:  deviance = 5.2292e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.24   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     943.32
Deviance             =  52.29247936               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.2252137               Pseudo R2       =     0.6336
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.375828   .0807118    17.05   0.000     1.217636     1.53402
         l_kijs19 |   2.566202   .0921636    27.84   0.000     2.385565     2.74684
            _cons |  -14.74435   .8010716   -18.41   0.000    -16.31443   -13.17428
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9933e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7050e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.6442e+01  eps = 3.65e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.54      
Iteration 4:   deviance = 5.3074e+01  eps = 6.35e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.73      
Iteration 5:   deviance = 5.2774e+01  eps = 5.68e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.53      
Iteration 6:   deviance = 5.2762e+01  eps = 2.22e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.01      
Iteration 7:   deviance = 5.2762e+01  eps = 3.62e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.17      
Iteration 8:   deviance = 5.2762e+01  eps = 1.11e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.18   S  
Iteration 9:   deviance = 5.2762e+01  eps = 2.41e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.18   S  
Iteration 10:  deviance = 5.2762e+01  eps = 1.39e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.18   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     913.72
Deviance             =  52.76190791               Prob > chi2     =     0.0000
Log pseudolikelihood =  -958.459928               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.401065   .0808047    17.34   0.000      1.24269    1.559439
         l_kijs20 |   2.428342   .0892143    27.22   0.000     2.253485    2.603199
            _cons |  -15.54486   .8058803   -19.29   0.000    -17.12435   -13.96536
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9970e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7463e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.6882e+01  eps = 3.62e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.56      
Iteration 4:   deviance = 5.3510e+01  eps = 6.30e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.76      
Iteration 5:   deviance = 5.3210e+01  eps = 5.64e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.56      
Iteration 6:   deviance = 5.3198e+01  eps = 2.20e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.04      
Iteration 7:   deviance = 5.3198e+01  eps = 3.59e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.19      
Iteration 8:   deviance = 5.3198e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.21   S  
Iteration 9:   deviance = 5.3198e+01  eps = 2.38e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.21   S  
Iteration 10:  deviance = 5.3198e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.21   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     867.93
Deviance             =  53.19779536               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6778717               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.404929   .0805855    17.43   0.000     1.246984    1.562873
         l_kijs21 |   2.567693   .0975938    26.31   0.000     2.376412    2.758973
            _cons |  -15.83617   .8061241   -19.64   0.000    -17.41614   -14.25619
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9981e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.7635e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7128e+01  eps = 3.59e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.53      
Iteration 4:   deviance = 5.3774e+01  eps = 6.24e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.71      
Iteration 5:   deviance = 5.3475e+01  eps = 5.59e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.51      
Iteration 6:   deviance = 5.3464e+01  eps = 2.18e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.99      
Iteration 7:   deviance = 5.3464e+01  eps = 3.56e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.14      
Iteration 8:   deviance = 5.3464e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.16   S  
Iteration 9:   deviance = 5.3464e+01  eps = 2.33e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.16   S  
Iteration 10:  deviance = 5.3464e+01  eps = 1.37e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.16   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     837.91
Deviance             =  53.46359096               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8107695               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.423098   .0805692    17.66   0.000     1.265185    1.581011
         l_kijs22 |   2.398048   .0934862    25.65   0.000     2.214818    2.581277
            _cons |  -14.76502   .7969682   -18.53   0.000    -16.32705   -13.20299
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0004e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7846e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.06      
Iteration 3:   deviance = 5.7317e+01  eps = 3.58e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.57      
Iteration 4:   deviance = 5.3948e+01  eps = 6.24e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3648e+01  eps = 5.59e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.59      
Iteration 6:   deviance = 5.3636e+01  eps = 2.18e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 7:   deviance = 5.3636e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.3636e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.24   S  
Iteration 9:   deviance = 5.3636e+01  eps = 2.36e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.24   S  
Iteration 10:  deviance = 5.3636e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.24   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     808.50
Deviance             =  53.63609838               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8970232               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.413697   .0806091    17.54   0.000     1.255706    1.571688
         l_kijs23 |   2.672796   .1063791    25.13   0.000     2.464297    2.881295
            _cons |  -15.19144   .8010837   -18.96   0.000    -16.76153   -13.62134
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0106e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.64  P   
Iteration 2:   deviance = 7.9175e+01  eps = 1.54e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.01      
Iteration 3:   deviance = 5.9013e+01  eps = 3.42e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.46      
Iteration 4:   deviance = 5.5722e+01  eps = 5.91e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.63      
Iteration 5:   deviance = 5.5428e+01  eps = 5.31e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.42      
Iteration 6:   deviance = 5.5416e+01  eps = 2.06e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.90      
Iteration 7:   deviance = 5.5416e+01  eps = 3.37e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.05      
Iteration 8:   deviance = 5.5416e+01  eps = 1.01e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.06   S  
Iteration 9:   deviance = 5.5416e+01  eps = 2.11e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.06   S  
Iteration 10:  deviance = 5.5416e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.06   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     620.63
Deviance             =  55.41608046               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.7870143               Pseudo R2       =     0.6330
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.461429   .0805907    18.13   0.000     1.303474    1.619384
         l_kijs24 |   2.254898   .1088183    20.72   0.000     2.041618    2.468178
            _cons |  -14.96962   .7947816   -18.83   0.000    -16.52737   -13.41188
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0067e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.64  P   
Iteration 2:   deviance = 7.8699e+01  eps = 1.55e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.00      
Iteration 3:   deviance = 5.8419e+01  eps = 3.47e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.45      
Iteration 4:   deviance = 5.5104e+01  eps = 6.02e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.62      
Iteration 5:   deviance = 5.4808e+01  eps = 5.40e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.41      
Iteration 6:   deviance = 5.4797e+01  eps = 2.10e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.88      
Iteration 7:   deviance = 5.4797e+01  eps = 3.41e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.04      
Iteration 8:   deviance = 5.4797e+01  eps = 1.03e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.05   S  
Iteration 9:   deviance = 5.4797e+01  eps = 2.15e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.05   S  
Iteration 10:  deviance = 5.4797e+01  eps = 1.34e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.05   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     712.13
Deviance             =  54.79650967               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.4772289               Pseudo R2       =     0.6331
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.44311   .0801678    18.00   0.000     1.285984    1.600236
         l_kijs25 |   2.245504   .0981193    22.89   0.000     2.053194    2.437814
            _cons |   -16.4138   .8072019   -20.33   0.000    -17.99589   -14.83172
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9991e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.7799e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.02      
Iteration 3:   deviance = 5.7382e+01  eps = 3.56e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.48      
Iteration 4:   deviance = 5.4054e+01  eps = 6.16e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.65      
Iteration 5:   deviance = 5.3757e+01  eps = 5.53e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.44      
Iteration 6:   deviance = 5.3745e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.92      
Iteration 7:   deviance = 5.3745e+01  eps = 3.52e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 8:   deviance = 5.3745e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.08   S  
Iteration 9:   deviance = 5.3745e+01  eps = 2.25e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.08   S  
Iteration 10:  deviance = 5.3745e+01  eps = 1.37e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.08   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     810.27
Deviance             =  53.74491556               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.9514318               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.44411     .08102    17.82   0.000     1.285314    1.602907
         l_kijs26 |   2.154573   .0857273    25.13   0.000      1.98655    2.322595
            _cons |   -15.1096   .8023253   -18.83   0.000    -16.68213   -13.53707
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9942e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.7067e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.10      
Iteration 3:   deviance = 5.6364e+01  eps = 3.67e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.62      
Iteration 4:   deviance = 5.2964e+01  eps = 6.42e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.84      
Iteration 5:   deviance = 5.2661e+01  eps = 5.74e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.64      
Iteration 6:   deviance = 5.2650e+01  eps = 2.24e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.13      
Iteration 7:   deviance = 5.2649e+01  eps = 3.66e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.28      
Iteration 8:   deviance = 5.2649e+01  eps = 1.12e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.30   S  
Iteration 9:   deviance = 5.2649e+01  eps = 2.52e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.30   S  
Iteration 10:  deviance = 5.2649e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.30   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     908.75
Deviance             =  52.64938889               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.4036685               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.374334   .0805852    17.05   0.000      1.21639    1.532278
         l_kijs27 |   2.813043   .1034713    27.19   0.000     2.610243    3.015843
            _cons |   -15.6725   .8064131   -19.43   0.000    -17.25304   -14.09196
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0058e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8551e+01  eps = 1.55e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.8199e+01  eps = 3.50e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.51      
Iteration 4:   deviance = 5.4865e+01  eps = 6.08e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.70      
Iteration 5:   deviance = 5.4568e+01  eps = 5.45e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.49      
Iteration 6:   deviance = 5.4556e+01  eps = 2.12e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.97      
Iteration 7:   deviance = 5.4556e+01  eps = 3.45e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.13      
Iteration 8:   deviance = 5.4556e+01  eps = 1.04e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.14   S  
Iteration 9:   deviance = 5.4556e+01  eps = 2.21e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.14   S  
Iteration 10:  deviance = 5.4556e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.14   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     723.37
Deviance             =  54.55580666               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.3568774               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.433471   .0803875    17.83   0.000     1.275915    1.591028
         l_kijs28 |   2.490879   .1072234    23.23   0.000     2.280726    2.701033
            _cons |  -16.17276   .8073469   -20.03   0.000    -17.75513   -14.59039
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0034e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8268e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.7879e+01  eps = 3.52e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.50      
Iteration 4:   deviance = 5.4543e+01  eps = 6.12e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.69      
Iteration 5:   deviance = 5.4246e+01  eps = 5.48e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.48      
Iteration 6:   deviance = 5.4234e+01  eps = 2.13e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.96      
Iteration 7:   deviance = 5.4234e+01  eps = 3.48e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.12      
Iteration 8:   deviance = 5.4234e+01  eps = 1.05e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.13   S  
Iteration 9:   deviance = 5.4234e+01  eps = 2.24e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.13   S  
Iteration 10:  deviance = 5.4234e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.13   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     760.42
Deviance             =  54.23388634               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.1959172               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |    1.43876   .0805022    17.87   0.000     1.280979    1.596541
         l_kijs29 |   2.385985   .0992745    24.03   0.000     2.191411     2.58056
            _cons |  -15.26835   .7989168   -19.11   0.000     -16.8342    -13.7025
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0043e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8394e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.02      
Iteration 3:   deviance = 5.8038e+01  eps = 3.51e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.49      
Iteration 4:   deviance = 5.4710e+01  eps = 6.08e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.66      
Iteration 5:   deviance = 5.4413e+01  eps = 5.46e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.46      
Iteration 6:   deviance = 5.4401e+01  eps = 2.12e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.94      
Iteration 7:   deviance = 5.4401e+01  eps = 3.46e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.09      
Iteration 8:   deviance = 5.4401e+01  eps = 1.05e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.10   S  
Iteration 9:   deviance = 5.4401e+01  eps = 2.20e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.10   S  
Iteration 10:  deviance = 5.4401e+01  eps = 1.35e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.10   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     744.59
Deviance             =  54.40105674               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.2795024               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.442027   .0805296    17.91   0.000     1.284192    1.599862
         l_kijs30 |   2.335294   .0985146    23.71   0.000     2.142209    2.528379
            _cons |  -15.77168    .803587   -19.63   0.000    -17.34668   -14.19668
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9981e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7521e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.6895e+01  eps = 3.63e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.61      
Iteration 4:   deviance = 5.3504e+01  eps = 6.34e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.83      
Iteration 5:   deviance = 5.3203e+01  eps = 5.67e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.64      
Iteration 6:   deviance = 5.3191e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.12      
Iteration 7:   deviance = 5.3191e+01  eps = 3.60e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.28      
Iteration 8:   deviance = 5.3191e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.29   S  
Iteration 9:   deviance = 5.3191e+01  eps = 2.45e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.29   S  
Iteration 10:  deviance = 5.3191e+01  eps = 1.38e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.29   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     847.42
Deviance             =  53.19085224               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6744002               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.392396    .080721    17.25   0.000     1.234186    1.550607
         l_kijs31 |   2.834412     .10906    25.99   0.000     2.620658    3.048165
            _cons |   -15.9408   .8095458   -19.69   0.000    -17.52748   -14.35412
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9930e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.67  P   
Iteration 2:   deviance = 7.6876e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.13      
Iteration 3:   deviance = 5.6120e+01  eps = 3.70e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.65      
Iteration 4:   deviance = 5.2710e+01  eps = 6.47e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.88      
Iteration 5:   deviance = 5.2407e+01  eps = 5.78e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.68      
Iteration 6:   deviance = 5.2395e+01  eps = 2.26e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.17      
Iteration 7:   deviance = 5.2395e+01  eps = 3.69e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.33      
Iteration 8:   deviance = 5.2395e+01  eps = 1.14e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.34   S  
Iteration 9:   deviance = 5.2395e+01  eps = 2.59e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.34   S  
Iteration 10:  deviance = 5.2395e+01  eps = 1.40e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.34   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     922.20
Deviance             =  52.39454853               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.2762483               Pseudo R2       =     0.6336
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.360319   .0808399    16.83   0.000     1.201876    1.518762
         l_kijs32 |   2.925675   .1061524    27.56   0.000      2.71762     3.13373
            _cons |  -16.22986   .8143972   -19.93   0.000    -17.82605   -14.63367
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0034e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8212e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.7748e+01  eps = 3.54e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.55      
Iteration 4:   deviance = 5.4386e+01  eps = 6.18e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.76      
Iteration 5:   deviance = 5.4086e+01  eps = 5.54e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.56      
Iteration 6:   deviance = 5.4075e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.04      
Iteration 7:   deviance = 5.4074e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.20      
Iteration 8:   deviance = 5.4074e+01  eps = 1.07e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.21   S  
Iteration 9:   deviance = 5.4074e+01  eps = 2.31e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.21   S  
Iteration 10:  deviance = 5.4074e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.21   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     774.72
Deviance             =  54.07433071               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.1161394               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.414377   .0802147    17.63   0.000     1.257159    1.571595
         l_kijs33 |   2.682897   .1103304    24.32   0.000     2.466654    2.899141
            _cons |  -15.96331    .804021   -19.85   0.000    -17.53916   -14.38746
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0071e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8644e+01  eps = 1.55e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.8245e+01  eps = 3.50e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.57      
Iteration 4:   deviance = 5.4886e+01  eps = 6.12e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.4586e+01  eps = 5.49e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.59      
Iteration 6:   deviance = 5.4575e+01  eps = 2.13e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 7:   deviance = 5.4574e+01  eps = 3.47e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.23      
Iteration 8:   deviance = 5.4574e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.24   S  
Iteration 9:   deviance = 5.4574e+01  eps = 2.29e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.24   S  
Iteration 10:  deviance = 5.4574e+01  eps = 1.34e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.24   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     711.01
Deviance             =  54.57434539               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.3661467               Pseudo R2       =     0.6332
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.407007   .0800135    17.58   0.000     1.250184    1.563831
         l_kijs34 |   2.862998    .125237    22.86   0.000     2.617538    3.108458
            _cons |  -16.56912   .8103738   -20.45   0.000    -18.15742   -14.98082
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9949e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.7300e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.6793e+01  eps = 3.61e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.49      
Iteration 4:   deviance = 5.3449e+01  eps = 6.26e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.67      
Iteration 5:   deviance = 5.3151e+01  eps = 5.61e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.46      
Iteration 6:   deviance = 5.3139e+01  eps = 2.19e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.94      
Iteration 7:   deviance = 5.3139e+01  eps = 3.58e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.09      
Iteration 8:   deviance = 5.3139e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.11   S  
Iteration 9:   deviance = 5.3139e+01  eps = 2.32e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.11   S  
Iteration 10:  deviance = 5.3139e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.11   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     876.24
Deviance             =  53.13881652               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6483823               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.425805   .0809606    17.61   0.000     1.267125    1.584485
         l_kijs35 |   2.188476   .0827491    26.45   0.000      2.02629    2.350661
            _cons |  -15.16702   .8033361   -18.88   0.000    -16.74153   -13.59251
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0033e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.8197e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.06      
Iteration 3:   deviance = 5.7733e+01  eps = 3.54e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.56      
Iteration 4:   deviance = 5.4372e+01  eps = 6.18e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.77      
Iteration 5:   deviance = 5.4073e+01  eps = 5.54e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.58      
Iteration 6:   deviance = 5.4061e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.06      
Iteration 7:   deviance = 5.4061e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.21      
Iteration 8:   deviance = 5.4061e+01  eps = 1.07e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.23   S  
Iteration 9:   deviance = 5.4061e+01  eps = 2.31e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.23   S  
Iteration 10:  deviance = 5.4061e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.23   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     763.42
Deviance             =   54.0609029               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.1094255               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.419746   .0805468    17.63   0.000     1.261878    1.577615
         l_kijs36 |   2.695176   .1115243    24.17   0.000     2.476593     2.91376
            _cons |  -15.64244   .8041464   -19.45   0.000    -17.21854   -14.06634
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9972e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7564e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.04      
Iteration 3:   deviance = 5.7127e+01  eps = 3.58e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.52      
Iteration 4:   deviance = 5.3799e+01  eps = 6.19e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.69      
Iteration 5:   deviance = 5.3502e+01  eps = 5.56e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.49      
Iteration 6:   deviance = 5.3490e+01  eps = 2.17e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.96      
Iteration 7:   deviance = 5.3490e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.12      
Iteration 8:   deviance = 5.3490e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.13   S  
Iteration 9:   deviance = 5.3490e+01  eps = 2.31e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.13   S  
Iteration 10:  deviance = 5.3490e+01  eps = 1.37e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.13   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     816.53
Deviance             =  53.49023377               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8240909               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.438601   .0812912    17.70   0.000     1.279273    1.597929
         l_kijs37 |   2.209222   .0874431    25.26   0.000     2.037837    2.380608
            _cons |  -13.48562   .7961694   -16.94   0.000    -15.04609   -11.92516
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9962e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7320e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.6680e+01  eps = 3.64e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.60      
Iteration 4:   deviance = 5.3293e+01  eps = 6.36e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.81      
Iteration 5:   deviance = 5.2992e+01  eps = 5.69e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.62      
Iteration 6:   deviance = 5.2980e+01  eps = 2.22e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.10      
Iteration 7:   deviance = 5.2980e+01  eps = 3.62e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.26      
Iteration 8:   deviance = 5.2980e+01  eps = 1.11e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.27   S  
Iteration 9:   deviance = 5.2980e+01  eps = 2.46e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.27   S  
Iteration 10:  deviance = 5.2980e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.27   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     876.98
Deviance             =  52.97974109               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.5688446               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.391239   .0806712    17.25   0.000     1.233126    1.549351
         l_kijs38 |   2.736469   .1030693    26.55   0.000     2.534456    2.938481
            _cons |  -15.63804   .8062382   -19.40   0.000    -17.21824   -14.05784
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0023e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.65  P   
Iteration 2:   deviance = 7.8146e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.03      
Iteration 3:   deviance = 5.7736e+01  eps = 3.53e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.50      
Iteration 4:   deviance = 5.4398e+01  eps = 6.14e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.69      
Iteration 5:   deviance = 5.4100e+01  eps = 5.50e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.49      
Iteration 6:   deviance = 5.4088e+01  eps = 2.14e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.96      
Iteration 7:   deviance = 5.4088e+01  eps = 3.49e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.12      
Iteration 8:   deviance = 5.4088e+01  eps = 1.06e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.13   S  
Iteration 9:   deviance = 5.4088e+01  eps = 2.26e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.13   S  
Iteration 10:  deviance = 5.4088e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.13   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     776.19
Deviance             =  54.08815756               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.1230528               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.437668   .0803799    17.89   0.000     1.280126     1.59521
         l_kijs39 |   2.367184   .0973582    24.31   0.000     2.176365    2.558002
            _cons |  -14.66337   .7932195   -18.49   0.000    -16.21805   -13.10869
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9921e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.6869e+01  eps = 1.59e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.6186e+01  eps = 3.68e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.59      
Iteration 4:   deviance = 5.2799e+01  eps = 6.41e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.79      
Iteration 5:   deviance = 5.2498e+01  eps = 5.74e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.60      
Iteration 6:   deviance = 5.2486e+01  eps = 2.24e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.08      
Iteration 7:   deviance = 5.2486e+01  eps = 3.67e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.24      
Iteration 8:   deviance = 5.2486e+01  eps = 1.12e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.25   S  
Iteration 9:   deviance = 5.2486e+01  eps = 2.50e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.25   S  
Iteration 10:  deviance = 5.2486e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.25   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     931.22
Deviance             =  52.48568439               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.3218162               Pseudo R2       =     0.6336
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.380309   .0807001    17.10   0.000      1.22214    1.538478
         l_kijs40 |     2.6253   .0951056    27.60   0.000     2.438896    2.811704
            _cons |  -15.34067   .8045769   -19.07   0.000    -16.91761   -13.76373
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0002e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7802e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.06      
Iteration 3:   deviance = 5.7240e+01  eps = 3.59e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.57      
Iteration 4:   deviance = 5.3861e+01  eps = 6.27e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.3560e+01  eps = 5.61e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.59      
Iteration 6:   deviance = 5.3548e+01  eps = 2.18e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 7:   deviance = 5.3548e+01  eps = 3.56e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.23      
Iteration 8:   deviance = 5.3548e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.24   S  
Iteration 9:   deviance = 5.3548e+01  eps = 2.37e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.24   S  
Iteration 10:  deviance = 5.3548e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.24   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     829.60
Deviance             =  53.54804143               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.8529948               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.399332   .0803586    17.41   0.000     1.241832    1.556832
         l_kijs41 |   2.747363   .1076666    25.52   0.000     2.536341    2.958386
            _cons |  -16.59848   .8117719   -20.45   0.000    -18.18952   -15.00744
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0082e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.64  P   
Iteration 2:   deviance = 7.8886e+01  eps = 1.55e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.01      
Iteration 3:   deviance = 5.8674e+01  eps = 3.44e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.45      
Iteration 4:   deviance = 5.5377e+01  eps = 5.95e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.62      
Iteration 5:   deviance = 5.5083e+01  eps = 5.35e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.41      
Iteration 6:   deviance = 5.5071e+01  eps = 2.08e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.88      
Iteration 7:   deviance = 5.5071e+01  eps = 3.39e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.04      
Iteration 8:   deviance = 5.5071e+01  eps = 1.02e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.05   S  
Iteration 9:   deviance = 5.5071e+01  eps = 2.12e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.05   S  
Iteration 10:  deviance = 5.5071e+01  eps = 1.33e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.05   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     663.63
Deviance             =  55.07110613               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.6145271               Pseudo R2       =     0.6331
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.464022   .0807405    18.13   0.000     1.305773     1.62227
         l_kijs42 |    2.16649   .0992854    21.82   0.000     1.971894    2.361086
            _cons |  -14.95327    .796141   -18.78   0.000    -16.51368   -13.39287
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9981e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7557e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.7012e+01  eps = 3.60e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.59      
Iteration 4:   deviance = 5.3650e+01  eps = 6.27e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.80      
Iteration 5:   deviance = 5.3351e+01  eps = 5.62e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.60      
Iteration 6:   deviance = 5.3339e+01  eps = 2.19e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.08      
Iteration 7:   deviance = 5.3339e+01  eps = 3.59e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.24      
Iteration 8:   deviance = 5.3339e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.25   S  
Iteration 9:   deviance = 5.3339e+01  eps = 2.40e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.26   S  
Iteration 10:  deviance = 5.3339e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.26   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     816.78
Deviance             =  53.33884951               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.7483988               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.415346   .0813239    17.40   0.000     1.255955    1.574738
         l_kijs43 |   2.620145   .1030248    25.43   0.000      2.41822     2.82207
            _cons |  -14.44762    .802809   -18.00   0.000     -16.0211   -12.87415
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0100e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.64  P   
Iteration 2:   deviance = 7.9070e+01  eps = 1.54e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.02      
Iteration 3:   deviance = 5.8860e+01  eps = 3.43e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.49      
Iteration 4:   deviance = 5.5555e+01  eps = 5.95e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.67      
Iteration 5:   deviance = 5.5260e+01  eps = 5.35e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.47      
Iteration 6:   deviance = 5.5248e+01  eps = 2.08e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.94      
Iteration 7:   deviance = 5.5248e+01  eps = 3.39e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.10      
Iteration 8:   deviance = 5.5248e+01  eps = 1.02e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.11   S  
Iteration 9:   deviance = 5.5248e+01  eps = 2.14e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.11   S  
Iteration 10:  deviance = 5.5248e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.11   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     637.80
Deviance             =  55.24822854               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.7030883               Pseudo R2       =     0.6330
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.453905   .0805122    18.06   0.000     1.296104    1.611706
         l_kijs44 |   2.390731   .1129302    21.17   0.000     2.169392     2.61207
            _cons |  -14.85815   .7938316   -18.72   0.000    -16.41403   -13.30227
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0089e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.64  P   
Iteration 2:   deviance = 7.9014e+01  eps = 1.54e+00  iters = 3    tol = 1.0e-04  min(eta) =  -4.99      
Iteration 3:   deviance = 5.8843e+01  eps = 3.43e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.41      
Iteration 4:   deviance = 5.5556e+01  eps = 5.92e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.57      
Iteration 5:   deviance = 5.5262e+01  eps = 5.32e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.36      
Iteration 6:   deviance = 5.5251e+01  eps = 2.07e-04  iters = 3    tol = 1.0e-04  min(eta) =  -8.83      
Iteration 7:   deviance = 5.5250e+01  eps = 3.37e-06  iters = 2    tol = 1.0e-04  min(eta) =  -8.98      
Iteration 8:   deviance = 5.5250e+01  eps = 1.01e-08  iters = 2    tol = 1.0e-05  min(eta) =  -8.99   S  
Iteration 9:   deviance = 5.5250e+01  eps = 2.09e-13  iters = 2    tol = 1.0e-07  min(eta) =  -8.99   S  
Iteration 10:  deviance = 5.5250e+01  eps = 1.33e-16  iters = 2    tol = 1.0e-09  min(eta) =  -8.99   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     660.07
Deviance             =  55.25032682               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.7041375               Pseudo R2       =     0.6330
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.466785   .0801514    18.30   0.000     1.309691    1.623879
         l_kijs45 |   2.034576   .0945712    21.51   0.000      1.84922    2.219932
            _cons |  -14.68505   .7878399   -18.64   0.000    -16.22919   -13.14091
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0028e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.8068e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.7525e+01  eps = 3.57e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.62      
Iteration 4:   deviance = 5.4141e+01  eps = 6.25e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.86      
Iteration 5:   deviance = 5.3840e+01  eps = 5.60e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.67      
Iteration 6:   deviance = 5.3828e+01  eps = 2.18e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.15      
Iteration 7:   deviance = 5.3828e+01  eps = 3.55e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.31      
Iteration 8:   deviance = 5.3828e+01  eps = 1.09e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.32   S  
Iteration 9:   deviance = 5.3828e+01  eps = 2.42e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.32   S  
Iteration 10:  deviance = 5.3828e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.32   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     767.61
Deviance             =  53.82814769               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.9930479               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.404622   .0805737    17.43   0.000       1.2467    1.562543
         l_kijs46 |   2.939012   .1210064    24.29   0.000     2.701844     3.17618
            _cons |  -14.77712   .7983348   -18.51   0.000    -16.34183   -13.21241
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9947e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7209e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.05      
Iteration 3:   deviance = 5.6597e+01  eps = 3.64e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.55      
Iteration 4:   deviance = 5.3222e+01  eps = 6.34e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.74      
Iteration 5:   deviance = 5.2921e+01  eps = 5.68e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.54      
Iteration 6:   deviance = 5.2910e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.02      
Iteration 7:   deviance = 5.2909e+01  eps = 3.61e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.18      
Iteration 8:   deviance = 5.2909e+01  eps = 1.10e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.19   S  
Iteration 9:   deviance = 5.2909e+01  eps = 2.41e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.19   S  
Iteration 10:  deviance = 5.2909e+01  eps = 1.39e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.19   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     902.36
Deviance             =  52.90948388               Prob > chi2     =     0.0000
Log pseudolikelihood =  -958.533716               Pseudo R2       =     0.6335
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.397334    .080395    17.38   0.000     1.239762    1.554905
         l_kijs47 |    2.50433   .0930153    26.92   0.000     2.322024    2.686637
            _cons |  -15.45848   .8014322   -19.29   0.000    -17.02926    -13.8877
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 1.9975e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.7467e+01  eps = 1.58e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.08      
Iteration 3:   deviance = 5.6835e+01  eps = 3.63e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.60      
Iteration 4:   deviance = 5.3445e+01  eps = 6.34e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.82      
Iteration 5:   deviance = 5.3143e+01  eps = 5.67e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.63      
Iteration 6:   deviance = 5.3131e+01  eps = 2.21e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.11      
Iteration 7:   deviance = 5.3131e+01  eps = 3.61e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.27      
Iteration 8:   deviance = 5.3131e+01  eps = 1.11e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.28   S  
Iteration 9:   deviance = 5.3131e+01  eps = 2.46e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.28   S  
Iteration 10:  deviance = 5.3131e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.28   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     861.35
Deviance             =  53.13130648               Prob > chi2     =     0.0000
Log pseudolikelihood = -958.6446273               Pseudo R2       =     0.6334
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.390483   .0804657    17.28   0.000     1.232773    1.548192
         l_kijs48 |   2.794369   .1066739    26.20   0.000     2.585292    3.003446
            _cons |  -15.44996   .8028664   -19.24   0.000    -17.02355   -13.87637
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0023e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.8040e+01  eps = 1.57e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.07      
Iteration 3:   deviance = 5.7543e+01  eps = 3.56e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.59      
Iteration 4:   deviance = 5.4179e+01  eps = 6.21e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.81      
Iteration 5:   deviance = 5.3879e+01  eps = 5.56e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.61      
Iteration 6:   deviance = 5.3868e+01  eps = 2.17e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.10      
Iteration 7:   deviance = 5.3867e+01  eps = 3.54e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.25      
Iteration 8:   deviance = 5.3867e+01  eps = 1.08e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.27   S  
Iteration 9:   deviance = 5.3867e+01  eps = 2.36e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.27   S  
Iteration 10:  deviance = 5.3867e+01  eps = 1.36e-16  iters = 2    tol = 1.0e-09  min(eta) =  -9.27   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     762.50
Deviance             =  53.86733138               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.0126397               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.419852   .0810349    17.52   0.000     1.261026    1.578677
         l_kijs49 |   2.748112    .113243    24.27   0.000      2.52616    2.970065
            _cons |  -15.08402   .8041767   -18.76   0.000    -16.66018   -13.50786
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+
(dropped 137282 observations that are either singletons or separated by a fixed effect)
Iteration 1:   deviance = 2.0038e+02  eps = .         iters = 4    tol = 1.0e-04  min(eta) =  -3.66  P   
Iteration 2:   deviance = 7.8241e+01  eps = 1.56e+00  iters = 3    tol = 1.0e-04  min(eta) =  -5.06      
Iteration 3:   deviance = 5.7796e+01  eps = 3.54e-01  iters = 3    tol = 1.0e-04  min(eta) =  -6.57      
Iteration 4:   deviance = 5.4442e+01  eps = 6.16e-02  iters = 3    tol = 1.0e-04  min(eta) =  -7.78      
Iteration 5:   deviance = 5.4143e+01  eps = 5.52e-03  iters = 3    tol = 1.0e-04  min(eta) =  -8.59      
Iteration 6:   deviance = 5.4131e+01  eps = 2.15e-04  iters = 3    tol = 1.0e-04  min(eta) =  -9.07      
Iteration 7:   deviance = 5.4131e+01  eps = 3.51e-06  iters = 2    tol = 1.0e-04  min(eta) =  -9.22      
Iteration 8:   deviance = 5.4131e+01  eps = 1.07e-08  iters = 2    tol = 1.0e-05  min(eta) =  -9.24   S  
Iteration 9:   deviance = 5.4131e+01  eps = 2.32e-13  iters = 2    tol = 1.0e-07  min(eta) =  -9.24   S  
Iteration 10:  deviance = 5.4131e+01  eps = 0.00e+00  iters = 2    tol = 1.0e-09  min(eta) =  -9.24   S O
------------------------------------------------------------------------------------------------------------
(legend: p: exact partial-out   s: exact solver   h: step-halving   o: epsilon below tolerance)
Converged in 10 iterations and 27 HDFE sub-iterations (tol = 1.0e-08)

HDFE PPML regression                              No. of obs      =     24,030
Absorbing 2 HDFE groups                           Residual df     =     11,729
                                                  Wald chi2(2)    =     743.83
Deviance             =  54.13114717               Prob > chi2     =     0.0000
Log pseudolikelihood = -959.1445476               Pseudo R2       =     0.6333
-----------------------------------------------------------------------------------
                  |               Robust
           pi_ijs |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
------------------+----------------------------------------------------------------
l_city_skill_wage |   1.428212   .0808192    17.67   0.000     1.269809    1.586615
         l_kijs50 |   2.678602   .1125895    23.79   0.000      2.45793    2.899273
            _cons |  -14.71845    .798495   -18.43   0.000    -16.28347   -13.15343
-----------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
        feij |     12015           0       12015     |
        feis |       568         284         284     |
-----------------------------------------------------+

. 
. clear

. svmat coef_gravity
number of observations will be reset to 50
Press any key to continue, or Break to abort
number of observations (_N) was 0, now 50

. 
. save "$folder\Cleaned Data\coef_gravity_het_skill.dta",replace
file D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\coef_gravity_het_s
> kill.dta saved

. 
. 
end of do-file

. sum

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
coef_gravi~1 |         50    1.414326    .0284217   1.354668   1.466785
coef_gravi~2 |         50    2.544831    .2350736   2.034576   2.939012
coef_gravi~3 |         50   -15.28973    .6882116  -16.62506  -13.48562

. do "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity E
> quation\03.Solving_Model_het_skill.do"

. ***** Solving the Model                   *********
. ***** Zibin Huang 2019.12.20      *********
. 
. ***********************************************************************
. * Load Cleaned Migration Flow Data from Census 2010
. ***********************************************************************
. 
. clear

. set more off

. clear matrix

. clear mata

. 
. global folder "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model"

. cd "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity E
> quation"
D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\03.Estimation of the Gravity Equatio
> n

. 
. use "$folder\Cleaned Data\data_for_gravity_het_skill.dta",clear

. 
. ***********************************************************************
. * Setting Parameters (Derived from previous steps)
. ***********************************************************************
. local sigma=3

. local epsilon=1.41

. local beta=1.80

. 
. ***********************************************************************
. * Local Productivity
. ***********************************************************************
. egen living_skill=group(living_city college)

. bysort living_skill: egen resident_living=sum(mig_perturb)

. label var resident_living "Number of residents living in this city with this skill"

. bysort hukou_skill: egen resident_hukou=sum(mig_perturb)

. label var resident_hukou "Number of residents having Hukou of this city with this skill"

. 
. gen num_commuting=pi_ijs*resident_hukou

. 
. gen liv_num_local_stu_i=liv_local_family_city_low+liv_local_family_city_high

. gen liv_num_mig_stu_j=liv_mig_family_city_low+liv_mig_family_city_high

. gen liv_num_lb_stu_i=liv_left_family_city_low+liv_left_family_city_high

. gen liv_num_local_stu_i_high=liv_local_family_city_high

. gen liv_num_local_stu_i_low=liv_local_family_city_low

. gen liv_num_mig_stu_j_high=liv_mig_family_city_high

. gen liv_num_mig_stu_j_low=liv_mig_family_city_low

. gen liv_num_lb_stu_i_high=liv_left_family_city_high

. gen liv_num_lb_stu_i_low=liv_left_family_city_low

. 
. gen hk_num_local_stu_i=hk_local_family_city_low+hk_local_family_city_high

. gen hk_num_mig_stu_j=hk_mig_family_city_low+hk_mig_family_city_high

. gen hk_num_lb_stu_i=hk_left_family_city_low+hk_left_family_city_high

. gen hk_num_local_stu_i_high=hk_local_family_city_high

. gen hk_num_local_stu_i_low=hk_local_family_city_low

. gen hk_num_mig_stu_j_high=hk_mig_family_city_high

. gen hk_num_mig_stu_j_low=hk_mig_family_city_low

. gen hk_num_lb_stu_i_high=hk_left_family_city_high

. gen hk_num_lb_stu_i_low=hk_left_family_city_low

. 
. gen wage_high=city_skill_wage if college==1
(80,656 missing values generated)

. label var wage_high "High skill wage in this city"

. gen wage_low=city_skill_wage if college==0
(80,656 missing values generated)

. label var wage_low "Low skill wage in this city"

. gen living_resident_high=resident_living if college==1
(80,656 missing values generated)

. label var living_resident_high "High skill residents in this city"

. gen living_resident_low=resident_living if college==0
(80,656 missing values generated)

. label var living_resident_low "Low skill residents in this city"

. gen hukou_resident_high=resident_hukou if college==1
(80,656 missing values generated)

. label var hukou_resident_high "High skill Hukou holder of this city"

. gen hukou_resident_low=resident_hukou if college==0
(80,656 missing values generated)

. label var hukou_resident_low "Low skill Hukou holder of this city"

. xfill wage_high wage_low living_resident_high living_resident_low,i(living_city_num)

. xfill hukou_resident_high hukou_resident_low,i(hukou_city_num)

. 
. 
. /* Asj is the local productivity for workers with skill s in city j */
. gen temp=(wage_low*living_resident_low)/(wage_high*living_resident_high)

. gen Asj=city_skill_wage/((1+temp)^(1/(`sigma'-1))) if college==1
(80,656 missing values generated)

. replace Asj=city_skill_wage/((1+1/temp)^(1/(`sigma'-1))) if college==0
(80,656 real changes made)

. label var Asj "Productivity of this skill labor in this city"

. 
. gen A_high_j=Asj if college==1
(80,656 missing values generated)

. label var A_high_j "High skill productivity in this city"

. gen A_low_j=Asj if college==0
(80,656 missing values generated)

. label var A_low_j "Low skill productivity in this city"

. xfill A_high_j A_low_j,i(living_city_num)

. 
. ***********************************************************************
. * Migration Cost
. ***********************************************************************
. replace pi_ijs=0.000000001 if pi_ijs==0                                                                            
>                                      /* Impute pi_ijs for city-pair with zero migrants */
(147,165 real changes made)

. gen phi_is=(city_skill_wage*kijs^`beta')^`epsilon'/pi_ijs if living_city==hukou_city                    /* Use stay
> ers to calculate living city constant in the gravity equation */
(160,744 missing values generated)

. xfill phi_is,i(hukou_skill)

. 
. /* tau_ijs is the migration cost for workers with skill s migrating from city i to city j */
. gen tau_ijs=city_skill_wage*kijs^`beta'/((pi_ijs*phi_is)^(1/`epsilon'))

. replace tau_ijs=1 if  living_city==hukou_city                                                                      
>                              /* There is no iceberg migration cost for stayers */
(26 real changes made)

. label var tau_ijs "Migration cost from city j to city i for people with skill s"

. 
. 
. drop temp

. 
. save "$folder\Cleaned Data\data_for_counterfactual_het_skill.dta",replace
file D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\data_for_counterfa
> ctual_het_skill.dta saved

. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
end of do-file

. use "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\draw estimates.d
> ta"

. sum

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
          x1 |         50   -.5419118    .2951252  -1.317923  -.0024836
          x2 |         50   -1.086139    .4379812  -1.990665  -.2511101

. use "D:\Dropbox\Dropbox\My documents\Rochester\Left-behind Children Project\New_Model\Cleaned Data\draw estimates_h
> et_skill.dta"

. sum

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
          x1 |         50   -.5664968    .2886514  -1.262518  -.0404807
          x2 |         50     .248548    .1674773  -.0605834   .6575054
          x3 |         50    -1.07956    .4277692  -2.119349  -.2082572
          x4 |         50    .1093822      .17011  -.2220872   .4736314

. exit, clear
